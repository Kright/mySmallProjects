{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "I tried to change layers in trained network with lightweight layers.\n",
    "\n",
    "### Converting output\n",
    "Find eigenvalues of covariance matrix, count how many of them are not less than, for example, 0.001 of the biggest eigenvalue.\n",
    "So instead of ConvWide(x) we will have UpCh(DownCh(ConvWide(x))), where 'DownCh' decreases channels count and B increases back.\n",
    "After that I combine DownCh(ConvWide(x)), it's a linear operation, which could be recalculated to ConvNotSoWide(x)\n",
    "So result will be UpCh(ConvNotSoWide(x))\n",
    "\n",
    "## Results:\n",
    "\n",
    "Results are quite good. You could shrink wide model to more narrow architecture. Recomputing for weights is just working.\n",
    "Accuracy is the same as for narrow model trained from scratch.\n",
    "\n",
    "### Converting input: not implemented yet\n",
    "Same as previous, but for layer inputs.\n",
    "\n",
    "So ConvWide(x) could be replaced as ConvWide(UpCh(DownCh(x))) and recalculated as ConvNotSoWide(Down(Ch))\n",
    "\n",
    "In terms of pytorch idea 2 and 3 leads to the next replacement for `WideConv`:\n",
    "\n",
    "```Python\n",
    "nn.Sequential(\n",
    "    nn.Conv(in_ch, in_less_ch, kernel_size = 1, bias = False),\n",
    "    nn.Conv(in_less_ch, out_less_ch, kernel_size = 3, bias = False),\n",
    "    nn.Conv(out_less_ch, out_ch, kernel_size = 1, bias = True),\n",
    ")\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "901e8f4741957256"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from myutil import CovarianceAccumulator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:02:41.097315468Z",
     "start_time": "2023-07-02T15:02:40.484317898Z"
    }
   },
   "id": "2c702d1adc364035"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:02:41.137834540Z",
     "start_time": "2023-07-02T15:02:41.128917076Z"
    }
   },
   "id": "d9a6f6a83adb1785"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'1.13.1+cu117'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:02:41.158458800Z",
     "start_time": "2023-07-02T15:02:41.134512641Z"
    }
   },
   "id": "9731f2a221291baa"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='../models/mnist',\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='../models/mnist',\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:02:41.272689049Z",
     "start_time": "2023-07-02T15:02:41.145763073Z"
    }
   },
   "id": "df81a5a60f95b856"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class NpAccumulator:\n",
    "    def __init__(self):\n",
    "        self.arrays: List[np.ndarray] = []\n",
    "\n",
    "    def add(self, tensor: torch.Tensor):\n",
    "        self.arrays.append(tensor.cpu().detach().numpy())\n",
    "\n",
    "    @property\n",
    "    def np_arr(self) -> np.ndarray:\n",
    "        return np.concatenate(self.arrays, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:02:41.316690772Z",
     "start_time": "2023-07-02T15:02:41.275819526Z"
    }
   },
   "id": "46edcdddc6d46599"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class TrainHelper:\n",
    "    @staticmethod\n",
    "    def train(cnn: nn.Module,\n",
    "              *,\n",
    "              lr: float = 0.001,\n",
    "              epochs: int,\n",
    "              train_dataset: datasets.MNIST,\n",
    "              test_dataset: Optional[datasets.MNIST] = None,\n",
    "              print_results: bool = True,\n",
    "              batch_size: int,\n",
    "              device_name: str = 'cuda') -> List[float]:\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=1)\n",
    "\n",
    "        device = torch.device(device_name)\n",
    "\n",
    "        cnn.to(device)\n",
    "        cnn.train()\n",
    "\n",
    "        optimizer = torch.optim.Adam(cnn.parameters(), lr=lr)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        eval_results: List[float] = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in train_loader:\n",
    "                images = Variable(images.to(device))\n",
    "                labels = Variable(labels.to(device))\n",
    "\n",
    "                output = cnn(images)\n",
    "                loss = loss_func(output, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if test_dataset is not None:\n",
    "                eval_result = TrainHelper.test(cnn, test_dataset, device)\n",
    "                eval_results.append(eval_result)\n",
    "                if print_results:\n",
    "                    print(f\"epoch {epoch}, accuracy = {eval_result}, loss = {loss.detach()}\")\n",
    "                cnn.train()\n",
    "\n",
    "        return eval_results\n",
    "\n",
    "    @staticmethod\n",
    "    def test(cnn: nn.Module, test_dataset: datasets.MNIST, device=None) -> float:\n",
    "        cnn.eval()\n",
    "        loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=1)\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "\n",
    "        for images, labels in loader:\n",
    "            if device is not None:\n",
    "                images = images.to(device)\n",
    "\n",
    "            results = cnn(images)\n",
    "            predictions = results.detach().cpu().numpy().argmax(axis=1)\n",
    "            oks = (predictions == labels.numpy()).sum()\n",
    "            correct += oks\n",
    "            incorrect += len(predictions) - oks\n",
    "\n",
    "        return correct / (correct + incorrect)\n",
    "\n",
    "    @staticmethod\n",
    "    def train_models(models: List[nn.Module], device_name: str) -> Tuple[int, float]:\n",
    "        \"\"\"\n",
    "        generator yields pair (trainable parameters count, best accuracy) for each network\n",
    "        :param device_name: 'cuda' or 'cpu'\n",
    "        \"\"\"\n",
    "        assert len(models) > 0\n",
    "\n",
    "        for model in models:\n",
    "            start = time.time()\n",
    "            eval_results = TrainHelper.train(\n",
    "                cnn=model,\n",
    "                epochs=20,\n",
    "                train_dataset=train_data,\n",
    "                test_dataset=test_data,\n",
    "                batch_size=2048,\n",
    "                device_name=device_name,\n",
    "                print_results=False\n",
    "            )\n",
    "            end = time.time()\n",
    "            best_acc = max(eval_results)\n",
    "            params_count = TrainHelper.total_parameters_count(model)\n",
    "            print(f\"best accuracy = {best_acc}, parameters = {params_count}, training time = {end - start}\")\n",
    "            yield params_count, best_acc\n",
    "\n",
    "    @staticmethod\n",
    "    def total_parameters_count(model: nn.Module) -> int:\n",
    "        return sum(np.prod(p.size()) for p in model.parameters())\n",
    "\n",
    "    @staticmethod\n",
    "    def print_parameters(model: nn.Module):\n",
    "        print(f\"total parameters = {TrainHelper.total_parameters_count(model)}\")\n",
    "        for p in model.parameters():\n",
    "            print(f\"size {np.prod(p.size())}: {p.size()}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def eval_layer(cnn: nn.Module, x: np.ndarray, batch_size: int) -> np.ndarray:\n",
    "        acc = NpAccumulator()\n",
    "        for tensor in TrainHelper.cuda_tensors_from_numpy(x, batch_size):\n",
    "            acc.add(cnn(tensor))\n",
    "        return acc.np_arr\n",
    "    \n",
    "    @staticmethod\n",
    "    def compare_layers(layer1: nn.Module, layer2: nn.Module, x: np.ndarray, batch_size: int) -> float:\n",
    "        y1 = TrainHelper.eval_layer(layer1, x, batch_size)\n",
    "        y2 = TrainHelper.eval_layer(layer2, x, batch_size)\n",
    "        return ((y1 - y2) ** 2).mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def cuda_tensors_from_numpy(arr: np.ndarray, batch_size: int):\n",
    "        for i in range(arr.shape[0] // batch_size):\n",
    "            yield torch.from_numpy(arr[i * batch_size: (i + 1) * batch_size]).to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:02:41.316996386Z",
     "start_time": "2023-07-02T15:02:41.316534650Z"
    }
   },
   "id": "2aba42b5d5ca4f56"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class MyParallelLayer(nn.Module):\n",
    "    def __init__(self, real_layer: nn.Module):\n",
    "        super().__init__()\n",
    "        self.use_real_layer: bool = True\n",
    "        self.real_layer: nn.Module = real_layer\n",
    "        self.mirror_layer: Optional[nn.Module] = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.use_real_layer:\n",
    "            return self.real_layer(x)\n",
    "        else:\n",
    "            return self.mirror_layer(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:02:41.318124439Z",
     "start_time": "2023-07-02T15:02:41.316799603Z"
    }
   },
   "id": "e48942583b85ca81"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class MyConvModel(nn.Module):\n",
    "    def __init__(self, channels: int):\n",
    "        super(MyConvModel, self).__init__()\n",
    "\n",
    "        c = channels\n",
    "        self.layers = nn.Sequential(\n",
    "            *self.conv(1, c, kernel_size=3),  # 28 - 26\n",
    "            *self.conv(c, c, kernel_size=3),  # 26 - 24\n",
    "            nn.MaxPool2d(2),  # 24 - 12\n",
    "\n",
    "            *self.conv(c, c * 2, kernel_size=3),  # 12 - 10\n",
    "            *self.conv(c * 2, c * 2, kernel_size=3),  # 10 - 8\n",
    "            nn.MaxPool2d(2),  # 8 - 4\n",
    "\n",
    "            *self.conv(c * 2, c * 4, kernel_size=3),  # 4 - 2\n",
    "            *self.conv(c * 4, c * 4, kernel_size=2),  # 2 - 1\n",
    "\n",
    "            nn.Conv2d(c * 4, 10, kernel_size=1, padding='valid', bias=True),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def conv(self, in_ch: int, out_ch: int, *, kernel_size) -> List[nn.Module]:\n",
    "        return [\n",
    "            MyParallelLayer(nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding='valid', bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "            )),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def paraller_layers(self) -> List[MyParallelLayer]:\n",
    "        return [layer for layer in self.layers if isinstance(layer, MyParallelLayer)]\n",
    "\n",
    "    @property\n",
    "    def alt_losses(self) -> List[float]:\n",
    "        return [layer.last_loss for layer in self.layers if isinstance(layer, MyParallelLayer)]\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layers(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:02:41.319019729Z",
     "start_time": "2023-07-02T15:02:41.316951735Z"
    }
   },
   "id": "bfde7c162ca08abc"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model = MyConvModel(32).to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:02:42.190452161Z",
     "start_time": "2023-07-02T15:02:41.317159528Z"
    }
   },
   "id": "70d152fb0e63d4a0"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, accuracy = 0.6094, loss = 0.17913737893104553\n",
      "epoch 1, accuracy = 0.9802, loss = 0.06752708554267883\n",
      "epoch 2, accuracy = 0.9902, loss = 0.03562994673848152\n",
      "epoch 3, accuracy = 0.9898, loss = 0.041804224252700806\n",
      "epoch 4, accuracy = 0.9923, loss = 0.014046435244381428\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.6094, 0.9802, 0.9902, 0.9898, 0.9923]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainHelper.train(\n",
    "    model,\n",
    "    epochs=5,\n",
    "    train_dataset=train_data,\n",
    "    test_dataset=test_data,\n",
    "    batch_size=2048,\n",
    "    print_results=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:03:04.132842485Z",
     "start_time": "2023-07-02T15:02:42.192338813Z"
    }
   },
   "id": "f1ba54dd18a2b942"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, accuracy = 0.9937, loss = 0.013888739049434662\n",
      "epoch 1, accuracy = 0.9942, loss = 0.009143810719251633\n",
      "epoch 2, accuracy = 0.9943, loss = 0.011036340147256851\n",
      "epoch 3, accuracy = 0.9941, loss = 0.005964362993836403\n",
      "epoch 4, accuracy = 0.9948, loss = 0.005565876606851816\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.9937, 0.9942, 0.9943, 0.9941, 0.9948]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainHelper.train(\n",
    "    model,\n",
    "    lr=0.0001,\n",
    "    epochs=5,\n",
    "    train_dataset=train_data,\n",
    "    test_dataset=test_data,\n",
    "    batch_size=2048,\n",
    "    print_results=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:03:25.459104160Z",
     "start_time": "2023-07-02T15:03:04.131594870Z"
    }
   },
   "id": "1c38459db7fa7b34"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9948"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainHelper.test(model, test_data, device='cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:03:26.159706818Z",
     "start_time": "2023-07-02T15:03:25.455548850Z"
    }
   },
   "id": "9b39ae4a47aa42ef"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "MyConvModel(\n  (layers): Sequential(\n    (0): MyParallelLayer(\n      (real_layer): Sequential(\n        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=valid, bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): LeakyReLU(negative_slope=0.1)\n    (2): MyParallelLayer(\n      (real_layer): Sequential(\n        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=valid, bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (3): LeakyReLU(negative_slope=0.1)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): MyParallelLayer(\n      (real_layer): Sequential(\n        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid, bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): LeakyReLU(negative_slope=0.1)\n    (7): MyParallelLayer(\n      (real_layer): Sequential(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid, bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (8): LeakyReLU(negative_slope=0.1)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): MyParallelLayer(\n      (real_layer): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=valid, bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (11): LeakyReLU(negative_slope=0.1)\n    (12): MyParallelLayer(\n      (real_layer): Sequential(\n        (0): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=valid, bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (13): LeakyReLU(negative_slope=0.1)\n    (14): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n    (15): Flatten(start_dim=1, end_dim=-1)\n  )\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:03:26.165288162Z",
     "start_time": "2023-07-02T15:03:26.161361177Z"
    }
   },
   "id": "bbef70f9c1c60b10"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) -> (60000, 32, 26, 26)\n",
      "(60000, 32, 26, 26) -> (60000, 32, 24, 24)\n",
      "(60000, 32, 12, 12) -> (60000, 64, 10, 10)\n",
      "(60000, 64, 10, 10) -> (60000, 64, 8, 8)\n",
      "(60000, 64, 4, 4) -> (60000, 128, 2, 2)\n",
      "(60000, 128, 2, 2) -> (60000, 128, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_x():\n",
    "    for x, loader in torch.utils.data.DataLoader(train_data, batch_size=60000):\n",
    "        return x.numpy()\n",
    "\n",
    "@dataclass\n",
    "class InOut:\n",
    "    layer: MyParallelLayer\n",
    "    inp: np.ndarray\n",
    "    out: np.ndarray\n",
    "    inp_cov: CovarianceAccumulator\n",
    "    out_cov: CovarianceAccumulator\n",
    "    \n",
    "    @staticmethod\n",
    "    def calc() -> Dict[MyParallelLayer, 'InOut']:\n",
    "        x = get_x()\n",
    "        model.eval()\n",
    "        \n",
    "        result = {}\n",
    "        with torch.no_grad():\n",
    "            for layer in model.layers:\n",
    "                x_next = TrainHelper.eval_layer(layer, x, batch_size=6000)\n",
    "                if isinstance(layer, MyParallelLayer):\n",
    "                    result[layer] = InOut(\n",
    "                        layer, x, x_next, \n",
    "                        inp_cov=CovarianceAccumulator().add_samples(x, axis=1),\n",
    "                        out_cov=CovarianceAccumulator().add_samples(x_next, axis=1),\n",
    "                    )\n",
    "                    print(f\"{x.shape} -> {x_next.shape}\")\n",
    "                x = x_next\n",
    "        \n",
    "        model.train()\n",
    "        return result\n",
    "\n",
    "\n",
    "inouts = InOut.calc()    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T15:09:24.567701518Z",
     "start_time": "2023-07-02T15:03:26.164741846Z"
    }
   },
   "id": "d6fa47f9704ddd00"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def combine_conv_with_bn(conv: nn.Conv2d, bn: nn.BatchNorm2d) -> nn.Conv2d:\n",
    "    with torch.no_grad():\n",
    "        result = nn.Conv2d(\n",
    "            conv.in_channels,\n",
    "            conv.out_channels,\n",
    "            kernel_size=(conv.weight.size(2), conv.weight.size(3)),\n",
    "            bias=True,\n",
    "        )\n",
    "        \n",
    "        # var_sqrt = (1e-10 + bn.running_var.detach().sqrt())\n",
    "        var_sqrt = bn.running_var.detach().sqrt()\n",
    "        result.weight = nn.Parameter(\n",
    "            conv.weight.detach() * (bn.weight.detach() / var_sqrt)[:, None, None, None]\n",
    "        )\n",
    "        result.bias = nn.Parameter(\n",
    "            (bn.bias.detach() - bn.running_mean.detach() * bn.weight.detach() / var_sqrt)\n",
    "        )\n",
    "        \n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:37:22.749264289Z",
     "start_time": "2023-07-02T16:37:22.703656887Z"
    }
   },
   "id": "5fd092ab46ca71f7"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def combine_convs(conv0: nn.Conv2d, conv1: nn.Conv2d) -> nn.Conv2d:\n",
    "    assert conv0.bias is None, 'not supported yet'\n",
    "    w0 = conv0.weight.cpu().detach()\n",
    "    w1 = conv1.weight.cpu().detach()\n",
    "    assert w0.size(2) == 1 or w1.size(2) == 1, 'no more than one non point-wise convolution'\n",
    "    assert w0.size(3) == 1 or w1.size(3) == 1, 'no more than one non point-wise convolution'\n",
    "    with torch.no_grad():\n",
    "        w01 = torch.tensordot(w0, w1, dims=[[0], [1]])\n",
    "        w01 = torch.moveaxis(w01, 3, 0)\n",
    "        if w01.size(5) != 1:\n",
    "            w01 = torch.swapaxes(w01, 3, 5)\n",
    "        if w01.size(4) != 1:\n",
    "            w01 = torch.swapaxes(w01, 2, 4)\n",
    "        w01 = torch.reshape(w01, shape=[w01.size(i) for i in range(4)])\n",
    "\n",
    "    bias = conv1.bias \n",
    "    conv01 = nn.Conv2d(\n",
    "        in_channels=conv0.in_channels, \n",
    "        out_channels=conv1.out_channels,\n",
    "        kernel_size=(w01.size(2), w01.size(3)),\n",
    "        bias = bias is not None\n",
    "    )\n",
    "    \n",
    "    conv01.weight = nn.Parameter(w01.detach())\n",
    "    if bias is not None:\n",
    "        conv01.bias = nn.Parameter(bias.detach())\n",
    "        \n",
    "    return conv01"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:37:57.130488059Z",
     "start_time": "2023-07-02T16:37:57.082265610Z"
    }
   },
   "id": "2c27b8f96f694859"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def make_parallel_layer(layer: MyParallelLayer, mid_ch: int):\n",
    "    inout = inouts[layer]\n",
    "    real_as_conv: nn.Conv2d = combine_conv_with_bn(conv=layer.real_layer[0], bn=layer.real_layer[1])\n",
    "    conv_wide = nn.Conv2d(real_as_conv.in_channels, real_as_conv.out_channels, kernel_size=3, bias=False)\n",
    "    conv_downch = nn.Conv2d(real_as_conv.out_channels, mid_ch, kernel_size=1, bias=False)\n",
    "    conv_upch = nn.Conv2d(9, real_as_conv.out_channels, kernel_size=1, bias=True)\n",
    "\n",
    "    shift, m_to, m_back = inout.out_cov.to_eigenvalues_and_back(mid_ch)\n",
    "\n",
    "    conv_wide.weight = nn.Parameter(real_as_conv.weight.detach())\n",
    "\n",
    "    conv_downch.weight = nn.Parameter(torch.from_numpy(m_to.astype(np.float32).T[:, :, np.newaxis, np.newaxis]))\n",
    "\n",
    "    conv_upch.weight = nn.Parameter(torch.from_numpy(m_back.astype(np.float32).T[:, :, np.newaxis, np.newaxis]))\n",
    "    shift_after = shift - shift @ m_to @ m_back + real_as_conv.bias.cpu().detach().numpy() @ m_to @ m_back\n",
    "    conv_upch.bias = nn.Parameter(torch.from_numpy(shift_after.astype(np.float32)))\n",
    "    \n",
    "    layer.mirror_layer = nn.Sequential(\n",
    "        combine_convs(conv_wide, conv_downch),\n",
    "        conv_upch\n",
    "    ).to('cuda')\n",
    "    \n",
    "    model.eval()\n",
    "    diff = TrainHelper.compare_layers(layer.real_layer, layer.mirror_layer, inout.inp, batch_size=1000)\n",
    "    print(f\"diff = {diff}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:53:41.108522808Z",
     "start_time": "2023-07-02T16:53:41.061906815Z"
    }
   },
   "id": "1308b5eb9ceae614"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def shrink_layer(layer_no: int, mid_layers: int) -> np.ndarray:\n",
    "    eig = inouts[model.paraller_layers[layer_no]].out_cov.eigenvalues_normalized\n",
    "    make_parallel_layer(model.paraller_layers[layer_no], mid_layers)\n",
    "    print(f\"choosen eigenvalues weight = {np.sum(eig[0:mid_layers])}\")\n",
    "    return np.stack([eig, np.cumsum(eig)], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:53:41.584838432Z",
     "start_time": "2023-07-02T16:53:41.580400119Z"
    }
   },
   "id": "fc9f61a2e2b7e503"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 9.49143128536889e-08\n",
      "choosen eigenvalues weight = 1.0000000000001272\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 4.29704253e-01,  2.68115971e-01,  1.24157649e-01,\n         8.04575583e-02,  4.39040646e-02,  2.95081168e-02,\n         1.19096976e-02,  1.01697522e-02,  2.07293804e-03,\n         1.22863553e-13,  9.97315915e-14,  8.51974704e-14,\n         7.50987748e-14,  5.55099895e-14,  4.94501527e-14,\n         3.97690044e-14,  3.46198724e-14,  2.49301814e-14,\n         1.17608943e-14, -1.50150390e-15, -1.45516711e-14,\n        -1.84393761e-14, -2.25469884e-14, -3.53238128e-14,\n        -4.45581167e-14, -5.31659117e-14, -6.50267717e-14,\n        -7.99860865e-14, -8.36323688e-14, -8.82918775e-14,\n        -1.05560026e-13, -1.13744656e-13],\n       [ 4.29704253e-01,  6.97820224e-01,  8.21977872e-01,\n         9.02435431e-01,  9.46339495e-01,  9.75847612e-01,\n         9.87757310e-01,  9.97927062e-01,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00]])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink_layer(layer_no=0, mid_layers=9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:53:48.490150312Z",
     "start_time": "2023-07-02T16:53:42.966497288Z"
    }
   },
   "id": "ab5a27b3510af668"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.005448869429528713\n",
      "choosen eigenvalues weight = 0.994574078583633\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[2.81859026e-01, 1.98255604e-01, 1.51850699e-01, 7.84284897e-02,\n        6.57679001e-02, 5.68234519e-02, 3.15657182e-02, 2.04241435e-02,\n        1.83555612e-02, 1.42297051e-02, 1.35056943e-02, 9.21466554e-03,\n        9.20421064e-03, 8.24164731e-03, 6.68852106e-03, 5.77877249e-03,\n        5.47644385e-03, 4.15019355e-03, 3.73452905e-03, 3.07917536e-03,\n        2.65783320e-03, 2.08764606e-03, 1.75591597e-03, 1.43853129e-03,\n        1.25296900e-03, 9.36114113e-04, 7.75216381e-04, 6.38272178e-04,\n        5.82369053e-04, 4.95988521e-04, 4.51396236e-04, 2.93595937e-04],\n       [2.81859026e-01, 4.80114630e-01, 6.31965329e-01, 7.10393819e-01,\n        7.76161719e-01, 8.32985171e-01, 8.64550889e-01, 8.84975033e-01,\n        9.03330594e-01, 9.17560299e-01, 9.31065993e-01, 9.40280659e-01,\n        9.49484869e-01, 9.57726517e-01, 9.64415038e-01, 9.70193810e-01,\n        9.75670254e-01, 9.79820448e-01, 9.83554977e-01, 9.86634152e-01,\n        9.89291985e-01, 9.91379631e-01, 9.93135547e-01, 9.94574079e-01,\n        9.95827048e-01, 9.96763162e-01, 9.97538378e-01, 9.98176650e-01,\n        9.98759019e-01, 9.99255008e-01, 9.99706404e-01, 1.00000000e+00]])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink_layer(layer_no=1, mid_layers=24)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:54:54.292900994Z",
     "start_time": "2023-07-02T16:54:48.766848050Z"
    }
   },
   "id": "9a1efa655da23d6f"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.009351296350359917\n",
      "choosen eigenvalues weight = 0.9905895888614311\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[1.84476935e-01, 1.39537819e-01, 1.22777491e-01, 8.16121902e-02,\n        6.72731105e-02, 6.35277026e-02, 5.20721369e-02, 3.43373185e-02,\n        3.14075872e-02, 2.28305958e-02, 2.08568791e-02, 1.69634740e-02,\n        1.54627651e-02, 1.28149683e-02, 1.11716986e-02, 1.02963746e-02,\n        9.22164570e-03, 8.50079391e-03, 7.48350372e-03, 6.28762622e-03,\n        6.10840598e-03, 5.62741618e-03, 4.89596679e-03, 4.22434669e-03,\n        4.13916661e-03, 4.13396309e-03, 3.58474965e-03, 3.51951168e-03,\n        3.23601711e-03, 2.95594248e-03, 2.68639006e-03, 2.43302794e-03,\n        2.26231306e-03, 2.15242611e-03, 2.02204027e-03, 1.94405962e-03,\n        1.82328124e-03, 1.64219316e-03, 1.60803416e-03, 1.47816214e-03,\n        1.39105440e-03, 1.34731490e-03, 1.27644017e-03, 1.23373134e-03,\n        1.07354374e-03, 1.01312354e-03, 9.50283918e-04, 9.14066685e-04,\n        9.00739069e-04, 8.49435170e-04, 7.79678314e-04, 7.67677204e-04,\n        7.06470189e-04, 6.73503554e-04, 6.15284598e-04, 5.84790105e-04,\n        5.60820376e-04, 5.33257123e-04, 4.83140616e-04, 4.62312377e-04,\n        4.34066626e-04, 4.07855343e-04, 3.60081579e-04, 2.91298898e-04],\n       [1.84476935e-01, 3.24014754e-01, 4.46792245e-01, 5.28404435e-01,\n        5.95677546e-01, 6.59205248e-01, 7.11277385e-01, 7.45614704e-01,\n        7.77022291e-01, 7.99852887e-01, 8.20709766e-01, 8.37673240e-01,\n        8.53136005e-01, 8.65950973e-01, 8.77122672e-01, 8.87419047e-01,\n        8.96640692e-01, 9.05141486e-01, 9.12624990e-01, 9.18912616e-01,\n        9.25021022e-01, 9.30648438e-01, 9.35544405e-01, 9.39768752e-01,\n        9.43907918e-01, 9.48041882e-01, 9.51626631e-01, 9.55146143e-01,\n        9.58382160e-01, 9.61338102e-01, 9.64024492e-01, 9.66457520e-01,\n        9.68719833e-01, 9.70872260e-01, 9.72894300e-01, 9.74838359e-01,\n        9.76661641e-01, 9.78303834e-01, 9.79911868e-01, 9.81390030e-01,\n        9.82781085e-01, 9.84128399e-01, 9.85404840e-01, 9.86638571e-01,\n        9.87712115e-01, 9.88725238e-01, 9.89675522e-01, 9.90589589e-01,\n        9.91490328e-01, 9.92339763e-01, 9.93119441e-01, 9.93887119e-01,\n        9.94593589e-01, 9.95267092e-01, 9.95882377e-01, 9.96467167e-01,\n        9.97027987e-01, 9.97561245e-01, 9.98044385e-01, 9.98506698e-01,\n        9.98940764e-01, 9.99348620e-01, 9.99708701e-01, 1.00000000e+00]])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink_layer(layer_no=2, mid_layers=48)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:54:40.430990833Z",
     "start_time": "2023-07-02T16:54:38.756194987Z"
    }
   },
   "id": "d04d9cfbf072311a"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.014899151399731636\n",
      "choosen eigenvalues weight = 0.9847368993848389\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[1.47121074e-01, 1.16047351e-01, 1.08268925e-01, 1.05549985e-01,\n        8.42595544e-02, 5.70158770e-02, 5.16015245e-02, 4.64819724e-02,\n        3.33840008e-02, 2.50069074e-02, 2.13963120e-02, 1.83027418e-02,\n        1.55315358e-02, 1.31018583e-02, 1.14665500e-02, 1.06392946e-02,\n        8.61081684e-03, 8.18654076e-03, 7.99503403e-03, 7.61446938e-03,\n        6.61265831e-03, 6.37980679e-03, 5.26401955e-03, 4.86386753e-03,\n        4.83957078e-03, 4.44991545e-03, 4.17544895e-03, 4.04689046e-03,\n        3.76129715e-03, 3.38518269e-03, 3.35744393e-03, 3.08733753e-03,\n        2.94985462e-03, 2.85883876e-03, 2.57259405e-03, 2.45338984e-03,\n        2.39973318e-03, 2.29493874e-03, 2.19892180e-03, 2.02775154e-03,\n        1.90702084e-03, 1.84602403e-03, 1.76521028e-03, 1.66784037e-03,\n        1.57697698e-03, 1.51855034e-03, 1.46728612e-03, 1.42620402e-03,\n        1.36307912e-03, 1.26768920e-03, 1.22798461e-03, 1.21097098e-03,\n        1.12662137e-03, 1.09652334e-03, 9.89836398e-04, 9.22182112e-04,\n        8.56841925e-04, 8.54125572e-04, 8.19684883e-04, 8.03619846e-04,\n        7.68756892e-04, 7.10762464e-04, 6.33352268e-04, 6.11069630e-04],\n       [1.47121074e-01, 2.63168425e-01, 3.71437350e-01, 4.76987335e-01,\n        5.61246889e-01, 6.18262766e-01, 6.69864291e-01, 7.16346263e-01,\n        7.49730264e-01, 7.74737171e-01, 7.96133483e-01, 8.14436225e-01,\n        8.29967761e-01, 8.43069619e-01, 8.54536169e-01, 8.65175464e-01,\n        8.73786281e-01, 8.81972821e-01, 8.89967855e-01, 8.97582325e-01,\n        9.04194983e-01, 9.10574790e-01, 9.15838809e-01, 9.20702677e-01,\n        9.25542248e-01, 9.29992163e-01, 9.34167612e-01, 9.38214503e-01,\n        9.41975800e-01, 9.45360982e-01, 9.48718426e-01, 9.51805764e-01,\n        9.54755619e-01, 9.57614457e-01, 9.60187051e-01, 9.62640441e-01,\n        9.65040174e-01, 9.67335113e-01, 9.69534035e-01, 9.71561786e-01,\n        9.73468807e-01, 9.75314831e-01, 9.77080042e-01, 9.78747882e-01,\n        9.80324859e-01, 9.81843409e-01, 9.83310695e-01, 9.84736899e-01,\n        9.86099979e-01, 9.87367668e-01, 9.88595652e-01, 9.89806623e-01,\n        9.90933245e-01, 9.92029768e-01, 9.93019604e-01, 9.93941787e-01,\n        9.94798628e-01, 9.95652754e-01, 9.96472439e-01, 9.97276059e-01,\n        9.98044816e-01, 9.98755578e-01, 9.99388930e-01, 1.00000000e+00]])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink_layer(layer_no=3, mid_layers=48)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:55:01.716418914Z",
     "start_time": "2023-07-02T16:55:00.486037727Z"
    }
   },
   "id": "8801dbb86b612722"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.008490923792123795\n",
      "choosen eigenvalues weight = 0.9911743401075941\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[1.84385464e-01, 1.55088939e-01, 8.71673906e-02, 8.05175919e-02,\n        6.88854570e-02, 4.93061176e-02, 3.96039074e-02, 3.24921957e-02,\n        3.08897446e-02, 2.52436377e-02, 1.99384378e-02, 1.66164269e-02,\n        1.56344948e-02, 1.24548504e-02, 1.17167563e-02, 1.11647709e-02,\n        1.01345509e-02, 9.44358734e-03, 7.21642338e-03, 6.43273699e-03,\n        6.05714910e-03, 5.75158883e-03, 5.41072922e-03, 4.74186499e-03,\n        4.49168525e-03, 4.27619980e-03, 3.83842219e-03, 3.65897138e-03,\n        3.42196823e-03, 3.26155958e-03, 3.16222040e-03, 2.90211016e-03,\n        2.66146851e-03, 2.45721524e-03, 2.35589572e-03, 2.28768853e-03,\n        2.06125825e-03, 1.91944533e-03, 1.90335175e-03, 1.82857493e-03,\n        1.79258275e-03, 1.71763161e-03, 1.64722940e-03, 1.61676516e-03,\n        1.58946988e-03, 1.48425106e-03, 1.40671482e-03, 1.35445676e-03,\n        1.33558048e-03, 1.28045860e-03, 1.27585659e-03, 1.18238436e-03,\n        1.15087772e-03, 1.08376979e-03, 1.07774121e-03, 1.05507581e-03,\n        1.01457789e-03, 9.90227920e-04, 9.38629944e-04, 9.34131940e-04,\n        9.08596492e-04, 8.88309353e-04, 8.78775421e-04, 8.39757802e-04,\n        8.12635570e-04, 8.00834586e-04, 7.74849650e-04, 7.66139067e-04,\n        7.59768491e-04, 7.29501595e-04, 7.14092909e-04, 6.94060705e-04,\n        6.87501734e-04, 6.61930107e-04, 6.51497293e-04, 6.35660484e-04,\n        6.24864536e-04, 6.17186423e-04, 6.05134847e-04, 5.99194526e-04,\n        5.76775314e-04, 5.52898659e-04, 5.43868114e-04, 5.35645216e-04,\n        5.26367034e-04, 5.09638781e-04, 5.06545207e-04, 4.89599362e-04,\n        4.79446866e-04, 4.74328617e-04, 4.58289985e-04, 4.48059329e-04,\n        4.38010281e-04, 4.33588531e-04, 4.26963759e-04, 4.12761001e-04,\n        4.05166146e-04, 3.97372017e-04, 3.85673194e-04, 3.79514849e-04,\n        3.62961939e-04, 3.53338393e-04, 3.44752280e-04, 3.38585299e-04,\n        3.36554509e-04, 3.21076244e-04, 3.12536935e-04, 3.07074388e-04,\n        2.95964417e-04, 2.86106955e-04, 2.83862429e-04, 2.80564698e-04,\n        2.71610116e-04, 2.69524372e-04, 2.59101541e-04, 2.47963998e-04,\n        2.40312926e-04, 2.32370275e-04, 2.23514694e-04, 2.20382808e-04,\n        2.15962579e-04, 1.99856398e-04, 1.98221934e-04, 1.91749459e-04,\n        1.83207084e-04, 1.72102506e-04, 1.65860869e-04, 1.42813644e-04],\n       [1.84385464e-01, 3.39474403e-01, 4.26641794e-01, 5.07159386e-01,\n        5.76044843e-01, 6.25350960e-01, 6.64954868e-01, 6.97447063e-01,\n        7.28336808e-01, 7.53580446e-01, 7.73518883e-01, 7.90135310e-01,\n        8.05769805e-01, 8.18224656e-01, 8.29941412e-01, 8.41106183e-01,\n        8.51240734e-01, 8.60684321e-01, 8.67900744e-01, 8.74333481e-01,\n        8.80390630e-01, 8.86142219e-01, 8.91552949e-01, 8.96294814e-01,\n        9.00786499e-01, 9.05062699e-01, 9.08901121e-01, 9.12560092e-01,\n        9.15982060e-01, 9.19243620e-01, 9.22405840e-01, 9.25307951e-01,\n        9.27969419e-01, 9.30426634e-01, 9.32782530e-01, 9.35070219e-01,\n        9.37131477e-01, 9.39050922e-01, 9.40954274e-01, 9.42782849e-01,\n        9.44575432e-01, 9.46293063e-01, 9.47940293e-01, 9.49557058e-01,\n        9.51146528e-01, 9.52630779e-01, 9.54037493e-01, 9.55391950e-01,\n        9.56727531e-01, 9.58007989e-01, 9.59283846e-01, 9.60466230e-01,\n        9.61617108e-01, 9.62700878e-01, 9.63778619e-01, 9.64833695e-01,\n        9.65848273e-01, 9.66838501e-01, 9.67777131e-01, 9.68711262e-01,\n        9.69619859e-01, 9.70508168e-01, 9.71386944e-01, 9.72226702e-01,\n        9.73039337e-01, 9.73840172e-01, 9.74615021e-01, 9.75381160e-01,\n        9.76140929e-01, 9.76870430e-01, 9.77584523e-01, 9.78278584e-01,\n        9.78966086e-01, 9.79628016e-01, 9.80279513e-01, 9.80915174e-01,\n        9.81540038e-01, 9.82157225e-01, 9.82762360e-01, 9.83361554e-01,\n        9.83938329e-01, 9.84491228e-01, 9.85035096e-01, 9.85570741e-01,\n        9.86097108e-01, 9.86606747e-01, 9.87113292e-01, 9.87602892e-01,\n        9.88082339e-01, 9.88556667e-01, 9.89014957e-01, 9.89463017e-01,\n        9.89901027e-01, 9.90334615e-01, 9.90761579e-01, 9.91174340e-01,\n        9.91579506e-01, 9.91976878e-01, 9.92362551e-01, 9.92742066e-01,\n        9.93105028e-01, 9.93458367e-01, 9.93803119e-01, 9.94141704e-01,\n        9.94478259e-01, 9.94799335e-01, 9.95111872e-01, 9.95418946e-01,\n        9.95714911e-01, 9.96001018e-01, 9.96284880e-01, 9.96565445e-01,\n        9.96837055e-01, 9.97106579e-01, 9.97365681e-01, 9.97613645e-01,\n        9.97853958e-01, 9.98086328e-01, 9.98309843e-01, 9.98530226e-01,\n        9.98746188e-01, 9.98946045e-01, 9.99144266e-01, 9.99336016e-01,\n        9.99519223e-01, 9.99691325e-01, 9.99857186e-01, 1.00000000e+00]])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink_layer(layer_no=4, mid_layers=96)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:55:26.888226684Z",
     "start_time": "2023-07-02T16:55:26.639876125Z"
    }
   },
   "id": "b40f2fa536bb8f42"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.0050513772293925285\n",
      "choosen eigenvalues weight = 0.9955017697229525\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[1.36571249e-01, 1.29763431e-01, 1.13380778e-01, 1.06225043e-01,\n        1.04733834e-01, 9.88330742e-02, 8.68179328e-02, 8.23750389e-02,\n        7.25473235e-02, 8.20348927e-03, 1.93513623e-03, 1.84405279e-03,\n        1.68486348e-03, 1.56738244e-03, 1.55953029e-03, 1.43327481e-03,\n        1.35337515e-03, 1.33341209e-03, 1.26607967e-03, 1.25320561e-03,\n        1.22448376e-03, 1.16216758e-03, 1.14164923e-03, 1.09310273e-03,\n        1.06885901e-03, 1.02958300e-03, 9.76709062e-04, 9.40946720e-04,\n        9.28741242e-04, 9.02838013e-04, 8.78413417e-04, 8.64199838e-04,\n        8.31411977e-04, 7.97050214e-04, 7.86972696e-04, 7.82043599e-04,\n        7.40482828e-04, 7.27695212e-04, 7.21172425e-04, 6.95717507e-04,\n        6.87917520e-04, 6.81386033e-04, 6.60601103e-04, 6.41899503e-04,\n        6.31135369e-04, 6.16737145e-04, 6.06400919e-04, 5.94189938e-04,\n        5.71543358e-04, 5.57672054e-04, 5.55188477e-04, 5.47778843e-04,\n        5.28998454e-04, 5.21338721e-04, 5.08907344e-04, 4.97683777e-04,\n        4.76587097e-04, 4.60807660e-04, 4.44010686e-04, 4.40126390e-04,\n        4.35447959e-04, 4.30831364e-04, 4.26756870e-04, 4.00023649e-04,\n        3.95169369e-04, 3.88629215e-04, 3.82679816e-04, 3.78896529e-04,\n        3.69677682e-04, 3.66555827e-04, 3.59232221e-04, 3.56009669e-04,\n        3.38993944e-04, 3.36277397e-04, 3.26839766e-04, 3.25862956e-04,\n        3.15774436e-04, 3.09267779e-04, 3.02918698e-04, 2.98962984e-04,\n        2.94172396e-04, 2.87314398e-04, 2.82977132e-04, 2.78516954e-04,\n        2.75281932e-04, 2.65602538e-04, 2.62324777e-04, 2.54677428e-04,\n        2.50977847e-04, 2.47611500e-04, 2.38697821e-04, 2.35457116e-04,\n        2.27855487e-04, 2.23391035e-04, 2.18890421e-04, 2.06556617e-04,\n        2.04790131e-04, 2.01118084e-04, 1.92055057e-04, 1.89766112e-04,\n        1.84819812e-04, 1.83020786e-04, 1.79657880e-04, 1.74226354e-04,\n        1.68733386e-04, 1.67471452e-04, 1.61091316e-04, 1.59080494e-04,\n        1.52661556e-04, 1.51201544e-04, 1.47120546e-04, 1.42734345e-04,\n        1.37189263e-04, 1.30933563e-04, 1.29895797e-04, 1.26969087e-04,\n        1.23553243e-04, 1.16416076e-04, 1.14497718e-04, 1.11249554e-04,\n        1.09026654e-04, 1.07642693e-04, 1.01944172e-04, 9.58573930e-05,\n        9.04683639e-05, 8.38928074e-05, 8.11089400e-05, 7.80360963e-05],\n       [1.36571249e-01, 2.66334680e-01, 3.79715457e-01, 4.85940501e-01,\n        5.90674335e-01, 6.89507409e-01, 7.76325342e-01, 8.58700380e-01,\n        9.31247704e-01, 9.39451193e-01, 9.41386329e-01, 9.43230382e-01,\n        9.44915246e-01, 9.46482628e-01, 9.48042158e-01, 9.49475433e-01,\n        9.50828808e-01, 9.52162220e-01, 9.53428300e-01, 9.54681506e-01,\n        9.55905990e-01, 9.57068157e-01, 9.58209806e-01, 9.59302909e-01,\n        9.60371768e-01, 9.61401351e-01, 9.62378060e-01, 9.63319007e-01,\n        9.64247748e-01, 9.65150586e-01, 9.66029000e-01, 9.66893199e-01,\n        9.67724611e-01, 9.68521662e-01, 9.69308634e-01, 9.70090678e-01,\n        9.70831161e-01, 9.71558856e-01, 9.72280028e-01, 9.72975746e-01,\n        9.73663663e-01, 9.74345049e-01, 9.75005650e-01, 9.75647550e-01,\n        9.76278685e-01, 9.76895422e-01, 9.77501823e-01, 9.78096013e-01,\n        9.78667557e-01, 9.79225229e-01, 9.79780417e-01, 9.80328196e-01,\n        9.80857195e-01, 9.81378533e-01, 9.81887441e-01, 9.82385124e-01,\n        9.82861711e-01, 9.83322519e-01, 9.83766530e-01, 9.84206656e-01,\n        9.84642104e-01, 9.85072936e-01, 9.85499692e-01, 9.85899716e-01,\n        9.86294885e-01, 9.86683515e-01, 9.87066194e-01, 9.87445091e-01,\n        9.87814769e-01, 9.88181324e-01, 9.88540557e-01, 9.88896566e-01,\n        9.89235560e-01, 9.89571838e-01, 9.89898677e-01, 9.90224540e-01,\n        9.90540315e-01, 9.90849583e-01, 9.91152501e-01, 9.91451464e-01,\n        9.91745637e-01, 9.92032951e-01, 9.92315928e-01, 9.92594445e-01,\n        9.92869727e-01, 9.93135330e-01, 9.93397654e-01, 9.93652332e-01,\n        9.93903310e-01, 9.94150921e-01, 9.94389619e-01, 9.94625076e-01,\n        9.94852932e-01, 9.95076323e-01, 9.95295213e-01, 9.95501770e-01,\n        9.95706560e-01, 9.95907678e-01, 9.96099733e-01, 9.96289499e-01,\n        9.96474319e-01, 9.96657340e-01, 9.96836998e-01, 9.97011224e-01,\n        9.97179957e-01, 9.97347429e-01, 9.97508520e-01, 9.97667601e-01,\n        9.97820262e-01, 9.97971464e-01, 9.98118584e-01, 9.98261319e-01,\n        9.98398508e-01, 9.98529441e-01, 9.98659337e-01, 9.98786306e-01,\n        9.98909860e-01, 9.99026276e-01, 9.99140773e-01, 9.99252023e-01,\n        9.99361050e-01, 9.99468692e-01, 9.99570636e-01, 9.99666494e-01,\n        9.99756962e-01, 9.99840855e-01, 9.99921964e-01, 1.00000000e+00]])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink_layer(layer_no=5, mid_layers=96)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:55:31.518902308Z",
     "start_time": "2023-07-02T16:55:31.299237936Z"
    }
   },
   "id": "70237d435c2ce104"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def test_layers(mirror_count: int) -> float:\n",
    "    for i, layer in enumerate(model.paraller_layers):\n",
    "        layer.use_real_layer = i >= mirror_count\n",
    "    return TrainHelper.test(model, test_data, device='cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:55:41.168229972Z",
     "start_time": "2023-07-02T16:55:41.119973936Z"
    }
   },
   "id": "e5884b1798857506"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.9948, 0.9948, 0.995, 0.995, 0.9944, 0.9944, 0.9943]"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[test_layers(i) for i in range(7)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:55:46.934962813Z",
     "start_time": "2023-07-02T16:55:41.400873168Z"
    }
   },
   "id": "f891c7cffeb13b28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare accuracy\n",
    "Create architecture of shrinked model and train it from scratch."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31035c6847acfe9e"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, accuracy = 0.1135, loss = 0.18532802164554596\n",
      "epoch 1, accuracy = 0.9589, loss = 0.07008330523967743\n",
      "epoch 2, accuracy = 0.99, loss = 0.04463108256459236\n",
      "epoch 3, accuracy = 0.9885, loss = 0.03158889710903168\n",
      "epoch 4, accuracy = 0.9907, loss = 0.0327920988202095\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.1135, 0.9589, 0.99, 0.9885, 0.9907]"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyShrinkedConvModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        c = 32\n",
    "        self.layers = nn.Sequential(\n",
    "            *self.conv(1, 9, c, kernel_size=3),  # 28 - 26\n",
    "            *self.conv(c, 24, c, kernel_size=3),  # 26 - 24\n",
    "            nn.MaxPool2d(2),  # 24 - 12\n",
    "\n",
    "            *self.conv(c, 48, c * 2, kernel_size=3),  # 12 - 10\n",
    "            *self.conv(c * 2, 48, c * 2, kernel_size=3),  # 10 - 8\n",
    "            nn.MaxPool2d(2),  # 8 - 4\n",
    "\n",
    "            *self.conv(c * 2, 96, c * 4, kernel_size=3),  # 4 - 2\n",
    "            *self.conv(c * 4, 96, c * 4, kernel_size=2),  # 2 - 1\n",
    "\n",
    "            nn.Conv2d(c * 4, 10, kernel_size=1, padding='valid', bias=True),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def conv(self, in_ch: int, mid_ch: int, out_ch: int, *, kernel_size) -> List[nn.Module]:\n",
    "        return [\n",
    "            MyParallelLayer(nn.Sequential(\n",
    "                nn.Conv2d(in_ch, mid_ch, kernel_size=kernel_size, padding='valid', bias=False),\n",
    "                nn.Conv2d(mid_ch, out_ch, kernel_size=1, padding='valid', bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "            )),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def paraller_layers(self) -> List[MyParallelLayer]:\n",
    "        return [layer for layer in self.layers if isinstance(layer, MyParallelLayer)]\n",
    "\n",
    "    @property\n",
    "    def alt_losses(self) -> List[float]:\n",
    "        return [layer.last_loss for layer in self.layers if isinstance(layer, MyParallelLayer)]\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "shrinked_model = MyShrinkedConvModel().to('cuda')\n",
    "TrainHelper.train(\n",
    "    shrinked_model,\n",
    "    epochs=5,\n",
    "    train_dataset=train_data,\n",
    "    test_dataset=test_data,\n",
    "    batch_size=2048,\n",
    "    print_results=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:56:32.963607602Z",
     "start_time": "2023-07-02T16:56:10.148807977Z"
    }
   },
   "id": "3e734d969398ae62"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, accuracy = 0.9927, loss = 0.01813686452805996\n",
      "epoch 1, accuracy = 0.9932, loss = 0.020897528156638145\n",
      "epoch 2, accuracy = 0.9933, loss = 0.014707138761878014\n",
      "epoch 3, accuracy = 0.9943, loss = 0.011871189810335636\n",
      "epoch 4, accuracy = 0.9944, loss = 0.01109230611473322\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.9927, 0.9932, 0.9933, 0.9943, 0.9944]"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainHelper.train(\n",
    "    shrinked_model,\n",
    "    lr=0.0001,\n",
    "    epochs=5,\n",
    "    train_dataset=train_data,\n",
    "    test_dataset=test_data,\n",
    "    batch_size=2048,\n",
    "    print_results=True,\n",
    ")    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:56:54.967806988Z",
     "start_time": "2023-07-02T16:56:32.960617800Z"
    }
   },
   "id": "8eef81cae11a3bc4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
