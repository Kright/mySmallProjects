{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "I tried to change layers in trained network with lightweight layers.\n",
    "\n",
    "### Converting output\n",
    "Use PCA, find eigenvalues of covariance matrix, count how many of them are not less than 0.001 of the biggest eigenvalue.\n",
    "So instead of ConvWide(x) we will have UpCh(DownCh(ConvWide(x))), where 'DownCh' decreases channels count and B increases back.\n",
    "After that I combine DownCh(ConvWide(x)), it's a linear operation, which could be recalculated to ConvNotSoWide(x)\n",
    "So result will be UpCh(ConvNotSoWide(x))\n",
    "\n",
    "### Converting input: not implemented yet\n",
    "Same as previous, but for layer inputs.\n",
    "\n",
    "So ConvWide(x) will be replaced as ConvWide(UpCh(DownCh(x))) and recalculated as ConvNotSoWide(Down(Ch))\n",
    "\n",
    "In terms of pytorch idea 2 and 3 leads to the next replacement for `WideConv`:\n",
    "\n",
    "```Python\n",
    "nn.Sequential(\n",
    "    nn.Conv(in_ch, in_less_ch, kernel_size = 1, bias = False),\n",
    "    nn.Conv(in_less_ch, out_less_ch, kernel_size = 3, bias = False),\n",
    "    nn.Conv(out_less_ch, out_ch, kernel_size = 1, bias = True),\n",
    ")\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "901e8f4741957256"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "from typing import Dict, Optional, Tuple, List, Optional, Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from myutil import CovarianceAccumulator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:05:21.277328567Z",
     "start_time": "2023-07-01T15:05:20.113460249Z"
    }
   },
   "id": "2c702d1adc364035"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:05:21.317025414Z",
     "start_time": "2023-07-01T15:05:21.314136522Z"
    }
   },
   "id": "d9a6f6a83adb1785"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'1.13.1+cu117'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:05:21.335261998Z",
     "start_time": "2023-07-01T15:05:21.317310639Z"
    }
   },
   "id": "9731f2a221291baa"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='../models/mnist',\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='../models/mnist',\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:05:21.625039807Z",
     "start_time": "2023-07-01T15:05:21.335388501Z"
    }
   },
   "id": "df81a5a60f95b856"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class NpAccumulator:\n",
    "    def __init__(self):\n",
    "        self.arrays: List[np.ndarray] = []\n",
    "\n",
    "    def add(self, tensor: torch.Tensor):\n",
    "        self.arrays.append(tensor.cpu().detach().numpy())\n",
    "\n",
    "    @property\n",
    "    def np_arr(self) -> np.ndarray:\n",
    "        return np.concatenate(self.arrays, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:05:21.635464682Z",
     "start_time": "2023-07-01T15:05:21.627508261Z"
    }
   },
   "id": "46edcdddc6d46599"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class TrainHelper:\n",
    "    @staticmethod\n",
    "    def train(cnn: nn.Module,\n",
    "              *,\n",
    "              epochs: int,\n",
    "              train_dataset: datasets.MNIST,\n",
    "              test_dataset: Optional[datasets.MNIST] = None,\n",
    "              print_results: bool = True,\n",
    "              batch_size: int,\n",
    "              device_name: str = 'cuda') -> List[float]:\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=1)\n",
    "\n",
    "        device = torch.device(device_name)\n",
    "\n",
    "        cnn.to(device)\n",
    "        cnn.train()\n",
    "\n",
    "        optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        eval_results: List[float] = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in train_loader:\n",
    "                images = Variable(images.to(device))\n",
    "                labels = Variable(labels.to(device))\n",
    "\n",
    "                output = cnn(images)\n",
    "                loss = loss_func(output, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if test_dataset is not None:\n",
    "                eval_result = TrainHelper.test(cnn, test_dataset, device)\n",
    "                eval_results.append(eval_result)\n",
    "                if print_results:\n",
    "                    print(f\"epoch {epoch}, accuracy = {eval_result}, loss = {loss.detach()}\")\n",
    "                cnn.train()\n",
    "\n",
    "        return eval_results\n",
    "\n",
    "    @staticmethod\n",
    "    def test(cnn: nn.Module, test_dataset: datasets.MNIST, device=None) -> float:\n",
    "        cnn.eval()\n",
    "        loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=1)\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "\n",
    "        for images, labels in loader:\n",
    "            if device is not None:\n",
    "                images = images.to(device)\n",
    "\n",
    "            results = cnn(images)\n",
    "            predictions = results.detach().cpu().numpy().argmax(axis=1)\n",
    "            oks = (predictions == labels.numpy()).sum()\n",
    "            correct += oks\n",
    "            incorrect += len(predictions) - oks\n",
    "\n",
    "        return correct / (correct + incorrect)\n",
    "\n",
    "    @staticmethod\n",
    "    def train_models(models: List[nn.Module], device_name: str) -> Tuple[int, float]:\n",
    "        \"\"\"\n",
    "        generator yields pair (trainable parameters count, best accuracy) for each network\n",
    "        :param device_name: 'cuda' or 'cpu'\n",
    "        \"\"\"\n",
    "        assert len(models) > 0\n",
    "\n",
    "        for model in models:\n",
    "            start = time.time()\n",
    "            eval_results = TrainHelper.train(\n",
    "                cnn=model,\n",
    "                epochs=20,\n",
    "                train_dataset=train_data,\n",
    "                test_dataset=test_data,\n",
    "                batch_size=2048,\n",
    "                device_name=device_name,\n",
    "                print_results=False\n",
    "            )\n",
    "            end = time.time()\n",
    "            best_acc = max(eval_results)\n",
    "            params_count = TrainHelper.total_parameters_count(model)\n",
    "            print(f\"best accuracy = {best_acc}, parameters = {params_count}, training time = {end - start}\")\n",
    "            yield params_count, best_acc\n",
    "\n",
    "    @staticmethod\n",
    "    def total_parameters_count(model: nn.Module) -> int:\n",
    "        return sum(np.prod(p.size()) for p in model.parameters())\n",
    "\n",
    "    @staticmethod\n",
    "    def print_parameters(model: nn.Module):\n",
    "        print(f\"total parameters = {TrainHelper.total_parameters_count(model)}\")\n",
    "        for p in model.parameters():\n",
    "            print(f\"size {np.prod(p.size())}: {p.size()}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def eval_layer(cnn: nn.Module, x: np.ndarray, batch_size: int) -> np.ndarray:\n",
    "        acc = NpAccumulator()\n",
    "        for tensor in TrainHelper.cuda_tensors_from_numpy(x, batch_size):\n",
    "            acc.add(cnn(tensor))\n",
    "        return acc.np_arr\n",
    "    \n",
    "    @staticmethod\n",
    "    def compare_layers(layer1: nn.Module, layer2: nn.Module, x: np.ndarray, batch_size: int) -> float:\n",
    "        y1 = TrainHelper.eval_layer(layer1, x, batch_size)\n",
    "        y2 = TrainHelper.eval_layer(layer2, x, batch_size)\n",
    "        return ((y1 - y2) ** 2).mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def cuda_tensors_from_numpy(arr: np.ndarray, batch_size: int):\n",
    "        for i in range(arr.shape[0] // batch_size):\n",
    "            yield torch.from_numpy(arr[i * batch_size: (i + 1) * batch_size]).to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T16:06:37.248945700Z",
     "start_time": "2023-07-01T16:06:37.234807343Z"
    }
   },
   "id": "2aba42b5d5ca4f56"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class MyParallelLayer(nn.Module):\n",
    "    def __init__(self, real_layer: nn.Module):\n",
    "        super().__init__()\n",
    "        self.use_real_layer: bool = True\n",
    "        self.real_layer: nn.Module = real_layer\n",
    "        self.mirror_layer: Optional[nn.Module] = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.use_real_layer:\n",
    "            return self.real_layer(x)\n",
    "        else:\n",
    "            return self.mirror_layer(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:05:21.671682087Z",
     "start_time": "2023-07-01T15:05:21.647579118Z"
    }
   },
   "id": "e48942583b85ca81"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class MyConvModel(nn.Module):\n",
    "    def __init__(self, channels: int):\n",
    "        super(MyConvModel, self).__init__()\n",
    "\n",
    "        c = channels\n",
    "        self.layers = nn.Sequential(\n",
    "            *self.conv(1, c, kernel_size=3),  # 28 - 26\n",
    "            *self.conv(c, c, kernel_size=3),  # 26 - 24\n",
    "            nn.MaxPool2d(2),  # 24 - 12\n",
    "\n",
    "            *self.conv(c, c * 2, kernel_size=3),  # 12 - 10\n",
    "            *self.conv(c * 2, c * 2, kernel_size=3),  # 10 - 8\n",
    "            nn.MaxPool2d(2),  # 8 - 4\n",
    "\n",
    "            *self.conv(c * 2, c * 4, kernel_size=3),  # 4 - 2\n",
    "            *self.conv(c * 4, c * 4, kernel_size=2),  # 2 - 1\n",
    "\n",
    "            nn.Conv2d(c * 4, 10, kernel_size=1, padding='valid', bias=True),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def conv(self, in_ch: int, out_ch: int, *, kernel_size) -> List[nn.Module]:\n",
    "        return [\n",
    "            MyParallelLayer(nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding='valid', bias=True),\n",
    "                # nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding='valid', bias=False),\n",
    "                # nn.BatchNorm2d(out_ch),\n",
    "            )),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def paraller_layers(self) -> List[MyParallelLayer]:\n",
    "        return [layer for layer in self.layers if isinstance(layer, MyParallelLayer)]\n",
    "\n",
    "    @property\n",
    "    def alt_losses(self) -> List[float]:\n",
    "        return [layer.last_loss for layer in self.layers if isinstance(layer, MyParallelLayer)]\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layers(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:05:21.674319454Z",
     "start_time": "2023-07-01T15:05:21.663913269Z"
    }
   },
   "id": "bfde7c162ca08abc"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model = MyConvModel(32).to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:05:23.214041353Z",
     "start_time": "2023-07-01T15:05:21.673301666Z"
    }
   },
   "id": "70d152fb0e63d4a0"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, accuracy = 0.8929, loss = 0.438852459192276\n",
      "epoch 1, accuracy = 0.9435, loss = 0.2200377881526947\n",
      "epoch 2, accuracy = 0.9665, loss = 0.11827639490365982\n",
      "epoch 3, accuracy = 0.9742, loss = 0.06652519851922989\n",
      "epoch 4, accuracy = 0.9821, loss = 0.09297072887420654\n",
      "epoch 5, accuracy = 0.9793, loss = 0.04297684505581856\n",
      "epoch 6, accuracy = 0.9821, loss = 0.0517389252781868\n",
      "epoch 7, accuracy = 0.9856, loss = 0.05742797255516052\n",
      "epoch 8, accuracy = 0.9885, loss = 0.03669394180178642\n",
      "epoch 9, accuracy = 0.9891, loss = 0.05633099004626274\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.8929,\n 0.9435,\n 0.9665,\n 0.9742,\n 0.9821,\n 0.9793,\n 0.9821,\n 0.9856,\n 0.9885,\n 0.9891]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainHelper.train(\n",
    "    model,\n",
    "    epochs=10,\n",
    "    train_dataset=train_data,\n",
    "    test_dataset=test_data,\n",
    "    batch_size=2048,\n",
    "    print_results=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:06:09.158088318Z",
     "start_time": "2023-07-01T15:05:23.214280727Z"
    }
   },
   "id": "f1ba54dd18a2b942"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9891"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainHelper.test(model, test_data, device='cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:06:09.969906008Z",
     "start_time": "2023-07-01T15:06:09.157316014Z"
    }
   },
   "id": "9b39ae4a47aa42ef"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "MyParallelLayer(\n  (real_layer): Sequential(\n    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n  )\n)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.paraller_layers[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:06:09.970279085Z",
     "start_time": "2023-07-01T15:06:09.966545298Z"
    }
   },
   "id": "bbef70f9c1c60b10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_x():\n",
    "    for x, loader in torch.utils.data.DataLoader(train_data, batch_size=60000):\n",
    "        return x.numpy()\n",
    "\n",
    "@dataclass\n",
    "class InOut:\n",
    "    layer: MyParallelLayer\n",
    "    inp: np.ndarray\n",
    "    out: np.ndarray\n",
    "    inp_cov: CovarianceAccumulator\n",
    "    out_cov: CovarianceAccumulator\n",
    "    \n",
    "    @staticmethod\n",
    "    def calc() -> Dict[MyParallelLayer, 'InOut']:\n",
    "        x = get_x()\n",
    "        model.eval()\n",
    "        \n",
    "        result = {}\n",
    "        with torch.no_grad():\n",
    "            for layer in model.layers:\n",
    "                x_next = TrainHelper.eval_layer(layer, x, batch_size=6000)\n",
    "                if isinstance(layer, MyParallelLayer):\n",
    "                    result[layer] = InOut(\n",
    "                        layer, x, x_next, \n",
    "                        inp_cov=CovarianceAccumulator().add_samples(x, axis=1),\n",
    "                        out_cov=CovarianceAccumulator().add_samples(x_next, axis=1),\n",
    "                    )\n",
    "                    print(f\"{x.shape} -> {x_next.shape}\")\n",
    "                x = x_next\n",
    "        \n",
    "        model.train()\n",
    "        return result\n",
    "\n",
    "\n",
    "inouts = InOut.calc()    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6fa47f9704ddd00"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "5.672196456127747e-18"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = inouts[model.paraller_layers[0]][1][0:1, :, 0, 0]\n",
    "shift, m_to, m_back = inouts[model.paraller_layers[0]].out_cov.to_eigenvalues_and_back(9)\n",
    "\n",
    "restored = ((example - shift) @ m_to ) @ m_back + shift\n",
    "np.sum((example - restored)**2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T14:29:29.359388574Z",
     "start_time": "2023-07-01T14:29:29.343352731Z"
    }
   },
   "id": "f5687f522484a132"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "5.672196492102728e-18"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = inouts[model.paraller_layers[0]][1][0:1, :, 0, 0]\n",
    "shift, m_to, m_back = acc.to_eigenvalues_and_back(9)\n",
    "\n",
    "shift_after = shift - (shift @ m_to) @ m_back\n",
    "\n",
    "restored = example @ m_to @ m_back + shift_after\n",
    "np.sum((example - restored)**2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T14:42:44.429748186Z",
     "start_time": "2023-07-01T14:42:44.385923895Z"
    }
   },
   "id": "6ae170200721a015"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def combine_convs(conv0: nn.Conv2d, conv1: nn.Conv2d) -> nn.Conv2d:\n",
    "    assert conv0.bias is None, 'not supported yet'\n",
    "    w0 = conv0.weight.cpu().detach()\n",
    "    w1 = conv1.weight.cpu().detach()\n",
    "    assert w0.size(2) == 1 or w1.size(2) == 1, 'no more than one non point-wise convolution'\n",
    "    assert w0.size(3) == 1 or w1.size(3) == 1, 'no more than one non point-wise convolution'\n",
    "    with torch.no_grad():\n",
    "        w01 = torch.tensordot(w0, w1, dims=[[0], [1]])\n",
    "        w01 = torch.moveaxis(w01, 3, 0)\n",
    "        if w01.size(5) != 1:\n",
    "            w01 = torch.swapaxes(w01, 3, 5)\n",
    "        if w01.size(4) != 1:\n",
    "            w01 = torch.swapaxes(w01, 2, 4)\n",
    "        w01 = torch.reshape(w01, shape=[w01.size(i) for i in range(4)])\n",
    "\n",
    "    bias = conv1.bias \n",
    "    conv01 = nn.Conv2d(\n",
    "        in_channels=conv0.in_channels, \n",
    "        out_channels=conv1.out_channels,\n",
    "        kernel_size=(w01.size(2), w01.size(3)),\n",
    "        bias = bias is not None\n",
    "    )\n",
    "    \n",
    "    conv01.weight = nn.Parameter(w01)\n",
    "    if bias is not None:\n",
    "        conv01.bias = nn.Parameter(bias.detach())\n",
    "        \n",
    "    return conv01"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c27b8f96f694859"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_parallel_layer_v3(layer: MyParallelLayer, mid_ch: int):\n",
    "    inout = inouts[layer]\n",
    "    real_conv: nn.Conv2d = inout.layer.real_layer[0]\n",
    "    conv_wide = nn.Conv2d(real_conv.in_channels, real_conv.out_channels, kernel_size=3, bias=False)\n",
    "    conv_downch = nn.Conv2d(real_conv.out_channels, mid_ch, kernel_size=1, bias=False)\n",
    "    conv_upch = nn.Conv2d(9, real_conv.out_channels, kernel_size=1, bias=True)\n",
    "\n",
    "    shift, m_to, m_back = inout.out_cov.to_eigenvalues_and_back(mid_ch)\n",
    "    \n",
    "    conv_wide.weight = nn.Parameter(real_conv.weight.detach())\n",
    "    \n",
    "    conv_downch.weight = nn.Parameter(torch.from_numpy(m_to.astype(np.float32).T[:, :, np.newaxis, np.newaxis]))\n",
    "    \n",
    "    conv_upch.weight = nn.Parameter(torch.from_numpy(m_back.astype(np.float32).T[:, :, np.newaxis, np.newaxis]))\n",
    "    shift_after = shift - shift @ m_to @ m_back + real_conv.bias.cpu().detach().numpy() @ m_to @ m_back\n",
    "    conv_upch.bias = nn.Parameter(torch.from_numpy(shift_after.astype(np.float32)))\n",
    "    \n",
    "    layer.mirror_layer = nn.Sequential(\n",
    "        combine_convs(conv_wide, conv_downch),\n",
    "        conv_upch\n",
    "    ).to('cuda')\n",
    "    \n",
    "    model.eval()\n",
    "    diff = TrainHelper.compare_layers(layer.real_layer, layer.mirror_layer, inout.inp, batch_size=1000)\n",
    "    print(f\"diff = {diff}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1308b5eb9ceae614"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "make_parallel_layer_v3(model.paraller_layers[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be9fb9330bef338"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.9891, 0.9891)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.paraller_layers[0].use_real_layer = True\n",
    "acc_real = TrainHelper.test(model, test_data, device='cuda')\n",
    "model.paraller_layers[0].use_real_layer = False\n",
    "acc_fake = TrainHelper.test(model, test_data, device='cuda')\n",
    "acc_real, acc_fake"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T16:03:58.268302487Z",
     "start_time": "2023-07-01T16:03:56.609144884Z"
    }
   },
   "id": "3e1580ffed2dfc8c"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "array([7.21801990e-01, 1.91455742e-01, 5.65268987e-02, 1.85796809e-02,\n       5.34610336e-03, 2.01267471e-03, 1.20641796e-03, 6.34483205e-04,\n       4.62602565e-04, 4.08309667e-04, 3.27326782e-04, 2.22613143e-04,\n       1.95019735e-04, 1.33247302e-04, 1.16834259e-04, 9.62859578e-05,\n       6.82935015e-05, 5.93736429e-05, 5.77363589e-05, 4.82616588e-05,\n       3.95258291e-05, 3.52306002e-05, 3.29214845e-05, 2.69340636e-05,\n       2.03147854e-05, 1.69029318e-05, 1.61334960e-05, 1.35787066e-05,\n       1.13907037e-05, 1.06677627e-05, 9.24518569e-06, 7.25946034e-06])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig2 = inouts[model.paraller_layers[1]].out_cov.covariance_eigenvalues_normalized\n",
    "eig2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:03:18.933363268Z",
     "start_time": "2023-07-01T17:03:18.918099924Z"
    }
   },
   "id": "9a1efa655da23d6f"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9998945069677841"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(eig2[0 : 24])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:04:09.510119326Z",
     "start_time": "2023-07-01T17:04:09.503676670Z"
    }
   },
   "id": "ace1fb016f1550ab"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 3.7337347748689353e-05\n"
     ]
    }
   ],
   "source": [
    "make_parallel_layer_v3(model.paraller_layers[1], mid_ch=24)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:05:40.029580210Z",
     "start_time": "2023-07-01T17:05:33.853843634Z"
    }
   },
   "id": "1f841de6a9864605"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.9891, 0.9891, 0.989]"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_layers(mirror_count: int = 2) -> float:\n",
    "    for i, layer in enumerate(model.paraller_layers):\n",
    "        layer.use_real_layer = i >= mirror_count\n",
    "    return TrainHelper.test(model, test_data, device='cuda')\n",
    "\n",
    "[test_layers(i) for i in range(3)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:09:09.995271752Z",
     "start_time": "2023-07-01T17:09:07.506483228Z"
    }
   },
   "id": "56c9ecf94c95b079"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "array([3.98621153e-01, 3.17266506e-01, 1.57635545e-01, 5.98474561e-02,\n       3.03713952e-02, 1.48863100e-02, 8.98813380e-03, 3.59621111e-03,\n       2.08005192e-03, 1.52518295e-03, 1.17355143e-03, 7.21837250e-04,\n       6.33482410e-04, 4.77868832e-04, 3.14994616e-04, 2.35329196e-04,\n       1.64776569e-04, 1.34083996e-04, 1.25370560e-04, 1.08282432e-04,\n       9.66021730e-05, 8.56046465e-05, 7.40780945e-05, 6.69511216e-05,\n       6.10044431e-05, 5.96564364e-05, 5.04671822e-05, 4.99504145e-05,\n       4.47515962e-05, 4.11101845e-05, 3.92834768e-05, 3.14957778e-05,\n       3.06943620e-05, 2.87876921e-05, 2.67469199e-05, 2.33836573e-05,\n       2.28876734e-05, 2.15009870e-05, 2.05588511e-05, 2.01399175e-05,\n       1.82099134e-05, 1.61466538e-05, 1.60470239e-05, 1.26072783e-05,\n       1.18291653e-05, 1.11950646e-05, 1.02468106e-05, 9.83551262e-06,\n       9.37500363e-06, 9.06421014e-06, 8.25862275e-06, 7.31429400e-06,\n       6.72568918e-06, 6.32245518e-06, 6.17946466e-06, 5.63239661e-06,\n       5.60414212e-06, 4.89720508e-06, 4.40397453e-06, 3.82938937e-06,\n       3.73015224e-06, 3.51701446e-06, 3.19413626e-06, 2.65568343e-06])"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig3 = inouts[model.paraller_layers[2]].out_cov.covariance_eigenvalues_normalized\n",
    "eig3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:09:31.997288079Z",
     "start_time": "2023-07-01T17:09:31.948989670Z"
    }
   },
   "id": "60c8edc1f5871bd9"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9999092961663699"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(eig3[0:48])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:10:34.635737820Z",
     "start_time": "2023-07-01T17:10:34.624594278Z"
    }
   },
   "id": "3e525235a233be36"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.0001967307471204549\n"
     ]
    }
   ],
   "source": [
    "make_parallel_layer_v3(model.paraller_layers[2], 48)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:11:16.925978555Z",
     "start_time": "2023-07-01T17:11:14.830588010Z"
    }
   },
   "id": "7f33cf8d9137c4ed"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.9891, 0.9891, 0.989, 0.9892]"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[test_layers(i) for i in range(4)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:11:56.707078796Z",
     "start_time": "2023-07-01T17:11:53.500370198Z"
    }
   },
   "id": "94ba7ed412223744"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999152771902584\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([3.66725551e-01, 2.51428744e-01, 1.42088955e-01, 9.05062631e-02,\n       6.10640768e-02, 2.69974589e-02, 2.02198277e-02, 1.57382069e-02,\n       1.04477853e-02, 4.42133867e-03, 2.43355359e-03, 1.65977160e-03,\n       1.27007021e-03, 1.10580801e-03, 7.96767569e-04, 4.95258566e-04,\n       3.81705991e-04, 3.28707081e-04, 2.89658646e-04, 2.09699784e-04,\n       1.61241347e-04, 1.49700827e-04, 1.27559809e-04, 1.06041094e-04,\n       9.25884390e-05, 7.89887976e-05, 7.04337573e-05, 5.94126190e-05,\n       5.52904411e-05, 4.84235764e-05, 4.19588006e-05, 3.71376810e-05,\n       2.97058810e-05, 2.94681449e-05, 2.73750223e-05, 2.28806645e-05,\n       2.18899477e-05, 2.09659036e-05, 1.86513905e-05, 1.67675853e-05,\n       1.41510087e-05, 1.34653397e-05, 1.20864496e-05, 1.18601276e-05,\n       1.08535615e-05, 9.64599321e-06, 9.15571786e-06, 8.36891977e-06,\n       8.31144036e-06, 7.72269454e-06, 7.30881634e-06, 6.53522131e-06,\n       6.38056828e-06, 5.89283849e-06, 5.54023236e-06, 5.42166084e-06,\n       4.73699223e-06, 4.48508089e-06, 4.41633138e-06, 4.04414940e-06,\n       3.89963739e-06, 3.66870348e-06, 3.28833664e-06, 3.07010583e-06])"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig4 = inouts[model.paraller_layers[3]].out_cov.covariance_eigenvalues_normalized\n",
    "print(np.sum(eig4[0: 48]))\n",
    "eig4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:14:12.567745466Z",
     "start_time": "2023-07-01T17:14:12.536536254Z"
    }
   },
   "id": "d061a959f62c75ba"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.0013124644756317139\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.9891, 0.9891, 0.989, 0.9892, 0.9891]"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_parallel_layer_v3(model.paraller_layers[3], 48)\n",
    "[test_layers(i) for i in range(5)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:14:18.747100430Z",
     "start_time": "2023-07-01T17:14:13.384897788Z"
    }
   },
   "id": "42f7cd5f6ae91afc"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998843121887715\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([2.43690771e-01, 1.73586383e-01, 1.11664893e-01, 8.90731260e-02,\n       6.74945956e-02, 5.12942415e-02, 4.17527746e-02, 3.92276549e-02,\n       3.08176542e-02, 2.52081717e-02, 1.97083733e-02, 1.79131832e-02,\n       1.53828615e-02, 1.23680698e-02, 8.94442923e-03, 7.08214315e-03,\n       5.80210136e-03, 4.52001756e-03, 3.69312546e-03, 3.31474831e-03,\n       2.79704253e-03, 2.44696772e-03, 2.01795981e-03, 1.53979313e-03,\n       1.36174411e-03, 1.08393098e-03, 9.86231254e-04, 9.16796300e-04,\n       8.74226954e-04, 7.70646738e-04, 7.16569045e-04, 6.88808719e-04,\n       6.42453809e-04, 5.94571769e-04, 4.74879256e-04, 4.60719565e-04,\n       4.25142997e-04, 4.03016530e-04, 3.56473735e-04, 3.39513038e-04,\n       3.22476362e-04, 2.97842728e-04, 2.94394693e-04, 2.77438548e-04,\n       2.52162699e-04, 2.39222168e-04, 2.34437800e-04, 2.25015493e-04,\n       2.12013510e-04, 2.05108608e-04, 1.88855425e-04, 1.86559554e-04,\n       1.77778412e-04, 1.75313666e-04, 1.62507249e-04, 1.56938537e-04,\n       1.47433468e-04, 1.41748872e-04, 1.37876048e-04, 1.31131018e-04,\n       1.28669853e-04, 1.20048379e-04, 1.12908066e-04, 1.11351595e-04,\n       1.05212907e-04, 1.03363331e-04, 9.89159049e-05, 9.74244931e-05,\n       9.63402787e-05, 9.19360404e-05, 8.81363429e-05, 8.64923315e-05,\n       8.42084981e-05, 7.89827210e-05, 7.85470755e-05, 7.35127931e-05,\n       7.26798110e-05, 7.18015008e-05, 6.80469404e-05, 6.35714018e-05,\n       6.10990699e-05, 6.08240469e-05, 5.87362687e-05, 5.58082814e-05,\n       5.53771880e-05, 5.41097087e-05, 5.29735038e-05, 5.05491683e-05,\n       5.04060822e-05, 4.81046893e-05, 4.55509806e-05, 4.50194548e-05,\n       4.33430033e-05, 4.18490552e-05, 3.99846056e-05, 3.91426880e-05,\n       3.78245600e-05, 3.74731963e-05, 3.55812461e-05, 3.50820281e-05,\n       3.32731944e-05, 3.26938368e-05, 3.07547545e-05, 3.03207855e-05,\n       2.92557264e-05, 2.79977414e-05, 2.77309541e-05, 2.67936135e-05,\n       2.61674313e-05, 2.52111229e-05, 2.48377468e-05, 2.43815175e-05,\n       2.23331141e-05, 2.19165038e-05, 2.14527334e-05, 2.04933856e-05,\n       1.94947452e-05, 1.89792818e-05, 1.84386870e-05, 1.77360629e-05,\n       1.71874676e-05, 1.57472913e-05, 1.55599978e-05, 1.45948938e-05,\n       1.40399278e-05, 1.35686894e-05, 1.27239901e-05, 1.22655535e-05])"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig5 = inouts[model.paraller_layers[4]].out_cov.covariance_eigenvalues_normalized\n",
    "print(np.sum(eig5[0: 120]))\n",
    "eig5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:15:49.718344372Z",
     "start_time": "2023-07-01T17:15:49.672320995Z"
    }
   },
   "id": "1deea942b16e1ec3"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.0026109495665878057\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.9891, 0.9891, 0.989, 0.9892, 0.9891, 0.9891]"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_parallel_layer_v3(model.paraller_layers[4], 120)\n",
    "[test_layers(i) for i in range(6)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:16:16.134623167Z",
     "start_time": "2023-07-01T17:16:10.944572788Z"
    }
   },
   "id": "4a80c1b2d3cef3f8"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998760280751985\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([2.85275797e-01, 2.15411545e-01, 1.42798639e-01, 1.08577120e-01,\n       7.29416720e-02, 4.39001407e-02, 2.47902287e-02, 2.07809419e-02,\n       1.44208003e-02, 9.53332544e-03, 8.56598224e-03, 7.15373152e-03,\n       6.43379337e-03, 5.26924263e-03, 3.45413519e-03, 2.87227830e-03,\n       2.38438452e-03, 2.14197565e-03, 1.75961052e-03, 1.55965337e-03,\n       1.35720235e-03, 1.22384886e-03, 1.00196688e-03, 9.60871824e-04,\n       8.82959406e-04, 7.87697579e-04, 7.34013454e-04, 7.05988872e-04,\n       6.67132330e-04, 5.87881473e-04, 5.54149380e-04, 5.14772326e-04,\n       4.84256414e-04, 4.44633819e-04, 3.86901264e-04, 3.59703973e-04,\n       3.53053688e-04, 3.11276462e-04, 3.05259649e-04, 2.87851134e-04,\n       2.77231244e-04, 2.53441006e-04, 2.49156882e-04, 2.41988271e-04,\n       2.30228862e-04, 2.21777048e-04, 2.04725398e-04, 1.97476063e-04,\n       1.85942864e-04, 1.82984929e-04, 1.78949376e-04, 1.66212053e-04,\n       1.60145383e-04, 1.54094244e-04, 1.48235394e-04, 1.44568857e-04,\n       1.38778646e-04, 1.32863564e-04, 1.26052061e-04, 1.23019286e-04,\n       1.18996432e-04, 1.11770382e-04, 1.07339217e-04, 1.05558881e-04,\n       1.01645275e-04, 9.90622256e-05, 9.49893742e-05, 9.17761826e-05,\n       9.09228827e-05, 9.03686713e-05, 8.72491501e-05, 8.13490971e-05,\n       7.97800782e-05, 7.80956964e-05, 7.50324778e-05, 7.29305605e-05,\n       7.18090055e-05, 6.79333506e-05, 6.46356612e-05, 6.44061311e-05,\n       6.11805494e-05, 5.84274920e-05, 5.74566219e-05, 5.65547900e-05,\n       5.41093791e-05, 5.30211754e-05, 5.18864557e-05, 5.05241171e-05,\n       4.89411719e-05, 4.80902882e-05, 4.69436010e-05, 4.53138346e-05,\n       4.27647827e-05, 4.20994841e-05, 4.00009318e-05, 3.96485281e-05,\n       3.80482749e-05, 3.68395825e-05, 3.65198319e-05, 3.56268414e-05,\n       3.47570608e-05, 3.36662209e-05, 3.30483794e-05, 3.20500517e-05,\n       3.06683193e-05, 2.98848526e-05, 2.93041353e-05, 2.86722079e-05,\n       2.80068164e-05, 2.62200894e-05, 2.59542288e-05, 2.46590544e-05,\n       2.34425153e-05, 2.20146632e-05, 2.15480964e-05, 2.08087456e-05,\n       2.05718361e-05, 2.03941149e-05, 1.85649316e-05, 1.78533067e-05,\n       1.76849370e-05, 1.65972771e-05, 1.63713509e-05, 1.59221186e-05,\n       1.55403959e-05, 1.44668337e-05, 1.38588199e-05, 1.35301918e-05])"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig6 = inouts[model.paraller_layers[5]].out_cov.covariance_eigenvalues_normalized\n",
    "print(np.sum(eig6[0: 120]))\n",
    "eig6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:16:56.830283471Z",
     "start_time": "2023-07-01T17:16:56.806569806Z"
    }
   },
   "id": "17d5b0efe1f79e79"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.002402564976364374\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.9891, 0.9891, 0.989, 0.9892, 0.9891, 0.9891, 0.989]"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_parallel_layer_v3(model.paraller_layers[5], 120)\n",
    "[test_layers(i) for i in range(7)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:17:23.455961263Z",
     "start_time": "2023-07-01T17:17:17.569494046Z"
    }
   },
   "id": "62597820b5539cec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "887f0216912d9332"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
