{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "I tried to change layers in trained network with lightweight layers.\n",
    "\n",
    "### Converting output\n",
    "Find eigenvalues of covariance matrix, count how many of them are not less than, for example, 0.001 of the biggest eigenvalue.\n",
    "So instead of ConvWide(x) we will have UpCh(DownCh(ConvWide(x))), where 'DownCh' decreases channels count and B increases back.\n",
    "After that I combine DownCh(ConvWide(x)), it's a linear operation, which could be recalculated to ConvNotSoWide(x)\n",
    "So result will be UpCh(ConvNotSoWide(x))\n",
    "\n",
    "### Converting input: not implemented yet\n",
    "Same as previous, but for layer inputs.\n",
    "\n",
    "So ConvWide(x) could be replaced as ConvWide(UpCh(DownCh(x))) and recalculated as ConvNotSoWide(Down(Ch))\n",
    "\n",
    "In terms of pytorch idea 2 and 3 leads to the next replacement for `WideConv`:\n",
    "\n",
    "```Python\n",
    "nn.Sequential(\n",
    "    nn.Conv(in_ch, in_less_ch, kernel_size = 1, bias = False),\n",
    "    nn.Conv(in_less_ch, out_less_ch, kernel_size = 3, bias = False),\n",
    "    nn.Conv(out_less_ch, out_ch, kernel_size = 1, bias = True),\n",
    ")\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "901e8f4741957256"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "from typing import Dict, Optional, Tuple, List, Optional, Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from myutil import CovarianceAccumulator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:41:50.862309334Z",
     "start_time": "2023-07-01T17:41:50.125516946Z"
    }
   },
   "id": "2c702d1adc364035"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:41:50.899564179Z",
     "start_time": "2023-07-01T17:41:50.849984214Z"
    }
   },
   "id": "d9a6f6a83adb1785"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'1.13.1+cu117'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:41:50.904728740Z",
     "start_time": "2023-07-01T17:41:50.891004318Z"
    }
   },
   "id": "9731f2a221291baa"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='../models/mnist',\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='../models/mnist',\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:41:51.038012221Z",
     "start_time": "2023-07-01T17:41:50.902474117Z"
    }
   },
   "id": "df81a5a60f95b856"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class NpAccumulator:\n",
    "    def __init__(self):\n",
    "        self.arrays: List[np.ndarray] = []\n",
    "\n",
    "    def add(self, tensor: torch.Tensor):\n",
    "        self.arrays.append(tensor.cpu().detach().numpy())\n",
    "\n",
    "    @property\n",
    "    def np_arr(self) -> np.ndarray:\n",
    "        return np.concatenate(self.arrays, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:41:52.045327446Z",
     "start_time": "2023-07-01T17:41:52.024441174Z"
    }
   },
   "id": "46edcdddc6d46599"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class TrainHelper:\n",
    "    @staticmethod\n",
    "    def train(cnn: nn.Module,\n",
    "              *,\n",
    "              lr: float = 0.001,\n",
    "              epochs: int,\n",
    "              train_dataset: datasets.MNIST,\n",
    "              test_dataset: Optional[datasets.MNIST] = None,\n",
    "              print_results: bool = True,\n",
    "              batch_size: int,\n",
    "              device_name: str = 'cuda') -> List[float]:\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=1)\n",
    "\n",
    "        device = torch.device(device_name)\n",
    "\n",
    "        cnn.to(device)\n",
    "        cnn.train()\n",
    "\n",
    "        optimizer = torch.optim.Adam(cnn.parameters(), lr=lr)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        eval_results: List[float] = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in train_loader:\n",
    "                images = Variable(images.to(device))\n",
    "                labels = Variable(labels.to(device))\n",
    "\n",
    "                output = cnn(images)\n",
    "                loss = loss_func(output, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if test_dataset is not None:\n",
    "                eval_result = TrainHelper.test(cnn, test_dataset, device)\n",
    "                eval_results.append(eval_result)\n",
    "                if print_results:\n",
    "                    print(f\"epoch {epoch}, accuracy = {eval_result}, loss = {loss.detach()}\")\n",
    "                cnn.train()\n",
    "\n",
    "        return eval_results\n",
    "\n",
    "    @staticmethod\n",
    "    def test(cnn: nn.Module, test_dataset: datasets.MNIST, device=None) -> float:\n",
    "        cnn.eval()\n",
    "        loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=1)\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "\n",
    "        for images, labels in loader:\n",
    "            if device is not None:\n",
    "                images = images.to(device)\n",
    "\n",
    "            results = cnn(images)\n",
    "            predictions = results.detach().cpu().numpy().argmax(axis=1)\n",
    "            oks = (predictions == labels.numpy()).sum()\n",
    "            correct += oks\n",
    "            incorrect += len(predictions) - oks\n",
    "\n",
    "        return correct / (correct + incorrect)\n",
    "\n",
    "    @staticmethod\n",
    "    def train_models(models: List[nn.Module], device_name: str) -> Tuple[int, float]:\n",
    "        \"\"\"\n",
    "        generator yields pair (trainable parameters count, best accuracy) for each network\n",
    "        :param device_name: 'cuda' or 'cpu'\n",
    "        \"\"\"\n",
    "        assert len(models) > 0\n",
    "\n",
    "        for model in models:\n",
    "            start = time.time()\n",
    "            eval_results = TrainHelper.train(\n",
    "                cnn=model,\n",
    "                epochs=20,\n",
    "                train_dataset=train_data,\n",
    "                test_dataset=test_data,\n",
    "                batch_size=2048,\n",
    "                device_name=device_name,\n",
    "                print_results=False\n",
    "            )\n",
    "            end = time.time()\n",
    "            best_acc = max(eval_results)\n",
    "            params_count = TrainHelper.total_parameters_count(model)\n",
    "            print(f\"best accuracy = {best_acc}, parameters = {params_count}, training time = {end - start}\")\n",
    "            yield params_count, best_acc\n",
    "\n",
    "    @staticmethod\n",
    "    def total_parameters_count(model: nn.Module) -> int:\n",
    "        return sum(np.prod(p.size()) for p in model.parameters())\n",
    "\n",
    "    @staticmethod\n",
    "    def print_parameters(model: nn.Module):\n",
    "        print(f\"total parameters = {TrainHelper.total_parameters_count(model)}\")\n",
    "        for p in model.parameters():\n",
    "            print(f\"size {np.prod(p.size())}: {p.size()}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def eval_layer(cnn: nn.Module, x: np.ndarray, batch_size: int) -> np.ndarray:\n",
    "        acc = NpAccumulator()\n",
    "        for tensor in TrainHelper.cuda_tensors_from_numpy(x, batch_size):\n",
    "            acc.add(cnn(tensor))\n",
    "        return acc.np_arr\n",
    "    \n",
    "    @staticmethod\n",
    "    def compare_layers(layer1: nn.Module, layer2: nn.Module, x: np.ndarray, batch_size: int) -> float:\n",
    "        y1 = TrainHelper.eval_layer(layer1, x, batch_size)\n",
    "        y2 = TrainHelper.eval_layer(layer2, x, batch_size)\n",
    "        return ((y1 - y2) ** 2).mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def cuda_tensors_from_numpy(arr: np.ndarray, batch_size: int):\n",
    "        for i in range(arr.shape[0] // batch_size):\n",
    "            yield torch.from_numpy(arr[i * batch_size: (i + 1) * batch_size]).to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:41:52.337108432Z",
     "start_time": "2023-07-01T17:41:52.307940169Z"
    }
   },
   "id": "2aba42b5d5ca4f56"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class MyParallelLayer(nn.Module):\n",
    "    def __init__(self, real_layer: nn.Module):\n",
    "        super().__init__()\n",
    "        self.use_real_layer: bool = True\n",
    "        self.real_layer: nn.Module = real_layer\n",
    "        self.mirror_layer: Optional[nn.Module] = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.use_real_layer:\n",
    "            return self.real_layer(x)\n",
    "        else:\n",
    "            return self.mirror_layer(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:41:54.692404451Z",
     "start_time": "2023-07-01T17:41:54.666113551Z"
    }
   },
   "id": "e48942583b85ca81"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class MyConvModel(nn.Module):\n",
    "    def __init__(self, channels: int):\n",
    "        super(MyConvModel, self).__init__()\n",
    "\n",
    "        c = channels\n",
    "        self.layers = nn.Sequential(\n",
    "            *self.conv(1, c, kernel_size=3),  # 28 - 26\n",
    "            *self.conv(c, c, kernel_size=3),  # 26 - 24\n",
    "            nn.MaxPool2d(2),  # 24 - 12\n",
    "\n",
    "            *self.conv(c, c * 2, kernel_size=3),  # 12 - 10\n",
    "            *self.conv(c * 2, c * 2, kernel_size=3),  # 10 - 8\n",
    "            nn.MaxPool2d(2),  # 8 - 4\n",
    "\n",
    "            *self.conv(c * 2, c * 4, kernel_size=3),  # 4 - 2\n",
    "            *self.conv(c * 4, c * 4, kernel_size=2),  # 2 - 1\n",
    "\n",
    "            nn.Conv2d(c * 4, 10, kernel_size=1, padding='valid', bias=True),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def conv(self, in_ch: int, out_ch: int, *, kernel_size) -> List[nn.Module]:\n",
    "        return [\n",
    "            MyParallelLayer(nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding='valid', bias=True),\n",
    "                # nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding='valid', bias=False),\n",
    "                # nn.BatchNorm2d(out_ch),\n",
    "            )),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def paraller_layers(self) -> List[MyParallelLayer]:\n",
    "        return [layer for layer in self.layers if isinstance(layer, MyParallelLayer)]\n",
    "\n",
    "    @property\n",
    "    def alt_losses(self) -> List[float]:\n",
    "        return [layer.last_loss for layer in self.layers if isinstance(layer, MyParallelLayer)]\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layers(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:41:59.034873001Z",
     "start_time": "2023-07-01T17:41:59.032338097Z"
    }
   },
   "id": "bfde7c162ca08abc"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = MyConvModel(32).to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:42:17.974272233Z",
     "start_time": "2023-07-01T17:42:17.941761056Z"
    }
   },
   "id": "70d152fb0e63d4a0"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, accuracy = 0.863, loss = 0.5057899951934814\n",
      "epoch 1, accuracy = 0.9319, loss = 0.2258572280406952\n",
      "epoch 2, accuracy = 0.9606, loss = 0.14280276000499725\n",
      "epoch 3, accuracy = 0.971, loss = 0.10730598866939545\n",
      "epoch 4, accuracy = 0.9785, loss = 0.07931938022375107\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.863, 0.9319, 0.9606, 0.971, 0.9785]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainHelper.train(\n",
    "    model,\n",
    "    epochs=5,\n",
    "    train_dataset=train_data,\n",
    "    test_dataset=test_data,\n",
    "    batch_size=2048,\n",
    "    print_results=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:42:54.697023365Z",
     "start_time": "2023-07-01T17:42:32.080822167Z"
    }
   },
   "id": "f1ba54dd18a2b942"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, accuracy = 0.9815, loss = 0.04147940129041672\n",
      "epoch 1, accuracy = 0.9827, loss = 0.060650743544101715\n",
      "epoch 2, accuracy = 0.9828, loss = 0.05440560728311539\n",
      "epoch 3, accuracy = 0.9838, loss = 0.05266561731696129\n",
      "epoch 4, accuracy = 0.9833, loss = 0.05502895265817642\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.9815, 0.9827, 0.9828, 0.9838, 0.9833]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainHelper.train(\n",
    "    model,\n",
    "    lr=0.0001,\n",
    "    epochs=5,\n",
    "    train_dataset=train_data,\n",
    "    test_dataset=test_data,\n",
    "    batch_size=2048,\n",
    "    print_results=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:43:17.260439569Z",
     "start_time": "2023-07-01T17:42:54.698387124Z"
    }
   },
   "id": "1c38459db7fa7b34"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9833"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainHelper.test(model, test_data, device='cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:43:18.044040504Z",
     "start_time": "2023-07-01T17:43:17.261731055Z"
    }
   },
   "id": "9b39ae4a47aa42ef"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "MyConvModel(\n  (layers): Sequential(\n    (0): MyParallelLayer(\n      (real_layer): Sequential(\n        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n      )\n    )\n    (1): LeakyReLU(negative_slope=0.1)\n    (2): MyParallelLayer(\n      (real_layer): Sequential(\n        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n      )\n    )\n    (3): LeakyReLU(negative_slope=0.1)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): MyParallelLayer(\n      (real_layer): Sequential(\n        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n      )\n    )\n    (6): LeakyReLU(negative_slope=0.1)\n    (7): MyParallelLayer(\n      (real_layer): Sequential(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n      )\n    )\n    (8): LeakyReLU(negative_slope=0.1)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): MyParallelLayer(\n      (real_layer): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n      )\n    )\n    (11): LeakyReLU(negative_slope=0.1)\n    (12): MyParallelLayer(\n      (real_layer): Sequential(\n        (0): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=valid)\n      )\n    )\n    (13): LeakyReLU(negative_slope=0.1)\n    (14): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n    (15): Flatten(start_dim=1, end_dim=-1)\n  )\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:43:18.063361038Z",
     "start_time": "2023-07-01T17:43:18.046023907Z"
    }
   },
   "id": "bbef70f9c1c60b10"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) -> (60000, 32, 26, 26)\n",
      "(60000, 32, 26, 26) -> (60000, 32, 24, 24)\n",
      "(60000, 32, 12, 12) -> (60000, 64, 10, 10)\n",
      "(60000, 64, 10, 10) -> (60000, 64, 8, 8)\n",
      "(60000, 64, 4, 4) -> (60000, 128, 2, 2)\n",
      "(60000, 128, 2, 2) -> (60000, 128, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_x():\n",
    "    for x, loader in torch.utils.data.DataLoader(train_data, batch_size=60000):\n",
    "        return x.numpy()\n",
    "\n",
    "@dataclass\n",
    "class InOut:\n",
    "    layer: MyParallelLayer\n",
    "    inp: np.ndarray\n",
    "    out: np.ndarray\n",
    "    inp_cov: CovarianceAccumulator\n",
    "    out_cov: CovarianceAccumulator\n",
    "    \n",
    "    @staticmethod\n",
    "    def calc() -> Dict[MyParallelLayer, 'InOut']:\n",
    "        x = get_x()\n",
    "        model.eval()\n",
    "        \n",
    "        result = {}\n",
    "        with torch.no_grad():\n",
    "            for layer in model.layers:\n",
    "                x_next = TrainHelper.eval_layer(layer, x, batch_size=6000)\n",
    "                if isinstance(layer, MyParallelLayer):\n",
    "                    result[layer] = InOut(\n",
    "                        layer, x, x_next, \n",
    "                        inp_cov=CovarianceAccumulator().add_samples(x, axis=1),\n",
    "                        out_cov=CovarianceAccumulator().add_samples(x_next, axis=1),\n",
    "                    )\n",
    "                    print(f\"{x.shape} -> {x_next.shape}\")\n",
    "                x = x_next\n",
    "        \n",
    "        model.train()\n",
    "        return result\n",
    "\n",
    "\n",
    "inouts = InOut.calc()    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:49:21.847072955Z",
     "start_time": "2023-07-01T17:43:18.053619322Z"
    }
   },
   "id": "d6fa47f9704ddd00"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def combine_convs(conv0: nn.Conv2d, conv1: nn.Conv2d) -> nn.Conv2d:\n",
    "    assert conv0.bias is None, 'not supported yet'\n",
    "    w0 = conv0.weight.cpu().detach()\n",
    "    w1 = conv1.weight.cpu().detach()\n",
    "    assert w0.size(2) == 1 or w1.size(2) == 1, 'no more than one non point-wise convolution'\n",
    "    assert w0.size(3) == 1 or w1.size(3) == 1, 'no more than one non point-wise convolution'\n",
    "    with torch.no_grad():\n",
    "        w01 = torch.tensordot(w0, w1, dims=[[0], [1]])\n",
    "        w01 = torch.moveaxis(w01, 3, 0)\n",
    "        if w01.size(5) != 1:\n",
    "            w01 = torch.swapaxes(w01, 3, 5)\n",
    "        if w01.size(4) != 1:\n",
    "            w01 = torch.swapaxes(w01, 2, 4)\n",
    "        w01 = torch.reshape(w01, shape=[w01.size(i) for i in range(4)])\n",
    "\n",
    "    bias = conv1.bias \n",
    "    conv01 = nn.Conv2d(\n",
    "        in_channels=conv0.in_channels, \n",
    "        out_channels=conv1.out_channels,\n",
    "        kernel_size=(w01.size(2), w01.size(3)),\n",
    "        bias = bias is not None\n",
    "    )\n",
    "    \n",
    "    conv01.weight = nn.Parameter(w01)\n",
    "    if bias is not None:\n",
    "        conv01.bias = nn.Parameter(bias.detach())\n",
    "        \n",
    "    return conv01"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:49:21.847343563Z",
     "start_time": "2023-07-01T17:49:21.825571698Z"
    }
   },
   "id": "2c27b8f96f694859"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def make_parallel_layer(layer: MyParallelLayer, mid_ch: int):\n",
    "    inout = inouts[layer]\n",
    "    real_conv: nn.Conv2d = inout.layer.real_layer[0]\n",
    "    conv_wide = nn.Conv2d(real_conv.in_channels, real_conv.out_channels, kernel_size=3, bias=False)\n",
    "    conv_downch = nn.Conv2d(real_conv.out_channels, mid_ch, kernel_size=1, bias=False)\n",
    "    conv_upch = nn.Conv2d(9, real_conv.out_channels, kernel_size=1, bias=True)\n",
    "\n",
    "    shift, m_to, m_back = inout.out_cov.to_eigenvalues_and_back(mid_ch)\n",
    "    \n",
    "    conv_wide.weight = nn.Parameter(real_conv.weight.detach())\n",
    "    \n",
    "    conv_downch.weight = nn.Parameter(torch.from_numpy(m_to.astype(np.float32).T[:, :, np.newaxis, np.newaxis]))\n",
    "    \n",
    "    conv_upch.weight = nn.Parameter(torch.from_numpy(m_back.astype(np.float32).T[:, :, np.newaxis, np.newaxis]))\n",
    "    shift_after = shift - shift @ m_to @ m_back + real_conv.bias.cpu().detach().numpy() @ m_to @ m_back\n",
    "    conv_upch.bias = nn.Parameter(torch.from_numpy(shift_after.astype(np.float32)))\n",
    "    \n",
    "    layer.mirror_layer = nn.Sequential(\n",
    "        combine_convs(conv_wide, conv_downch),\n",
    "        conv_upch\n",
    "    ).to('cuda')\n",
    "    \n",
    "    model.eval()\n",
    "    diff = TrainHelper.compare_layers(layer.real_layer, layer.mirror_layer, inout.inp, batch_size=1000)\n",
    "    print(f\"diff = {diff}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:49:21.847478902Z",
     "start_time": "2023-07-01T17:49:21.825717888Z"
    }
   },
   "id": "1308b5eb9ceae614"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def shrink_layer(layer_no: int, mid_layers: int) -> np.ndarray:\n",
    "    eig = inouts[model.paraller_layers[layer_no]].out_cov.covariance_eigenvalues_normalized\n",
    "    make_parallel_layer(model.paraller_layers[layer_no], mid_layers)\n",
    "    print(f\"choosen eigenvalues weight = {np.sum(eig[0:mid_layers])}\")\n",
    "    return np.stack([eig, np.cumsum(eig)], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:49:40.788019839Z",
     "start_time": "2023-07-01T17:49:40.766931493Z"
    }
   },
   "id": "fc9f61a2e2b7e503"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 1.3486904337271463e-15\n",
      "choosen eigenvalues weight = 0.9999999999997045\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 6.93579290e-01,  1.57256679e-01,  9.19444662e-02,\n         2.78612548e-02,  1.06627511e-02,  9.27248369e-03,\n         5.88955466e-03,  1.95233102e-03,  1.58118955e-03,\n         3.73497370e-13,  2.96235600e-13,  2.16443857e-13,\n         1.62406429e-13,  1.12770068e-13,  9.71151631e-14,\n         7.82251517e-14,  6.10534723e-14,  4.01548849e-14,\n         3.17610912e-14,  1.95409871e-14,  1.06333967e-14,\n        -1.86857989e-14, -3.61448670e-14, -3.96351742e-14,\n        -4.87957283e-14, -6.96424282e-14, -7.86779172e-14,\n        -8.81179782e-14, -1.20222649e-13, -1.60944379e-13,\n        -2.55296592e-13, -2.88083364e-13],\n       [ 6.93579290e-01,  8.50835969e-01,  9.42780435e-01,\n         9.70641690e-01,  9.81304441e-01,  9.90576925e-01,\n         9.96466479e-01,  9.98418810e-01,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  1.00000000e+00]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink_layer(layer_no=0, mid_layers=9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:49:47.396578036Z",
     "start_time": "2023-07-01T17:49:41.522522426Z"
    }
   },
   "id": "ab5a27b3510af668"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.00016169504669960588\n",
      "choosen eigenvalues weight = 0.9992694134739482\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[6.90872364e-01, 1.51875500e-01, 1.11305604e-01, 2.28447524e-02,\n        1.02340958e-02, 5.57610236e-03, 2.35518679e-03, 1.12360681e-03,\n        8.27294286e-04, 6.22440049e-04, 4.64976564e-04, 3.21633101e-04,\n        2.87125765e-04, 2.61755811e-04, 1.66492338e-04, 1.30483665e-04,\n        1.12538187e-04, 8.38287296e-05, 7.79653793e-05, 6.87447916e-05,\n        6.41351324e-05, 4.91414604e-05, 4.51465225e-05, 3.96403907e-05,\n        3.84260112e-05, 2.91558330e-05, 2.82666889e-05, 2.52277161e-05,\n        2.14428159e-05, 1.82928042e-05, 1.47147143e-05, 1.39193485e-05],\n       [6.90872364e-01, 8.42747864e-01, 9.54053468e-01, 9.76898220e-01,\n        9.87132316e-01, 9.92708418e-01, 9.95063605e-01, 9.96187212e-01,\n        9.97014506e-01, 9.97636946e-01, 9.98101923e-01, 9.98423556e-01,\n        9.98710682e-01, 9.98972437e-01, 9.99138930e-01, 9.99269413e-01,\n        9.99381952e-01, 9.99465780e-01, 9.99543746e-01, 9.99612491e-01,\n        9.99676626e-01, 9.99725767e-01, 9.99770914e-01, 9.99810554e-01,\n        9.99848980e-01, 9.99878136e-01, 9.99906403e-01, 9.99931630e-01,\n        9.99953073e-01, 9.99971366e-01, 9.99986081e-01, 1.00000000e+00]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink_layer(layer_no=1, mid_layers=16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:50:21.194796619Z",
     "start_time": "2023-07-01T17:50:14.943420155Z"
    }
   },
   "id": "9a1efa655da23d6f"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.0006230933358892798\n",
      "choosen eigenvalues weight = 0.9994686847903907\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[5.41107727e-01, 1.99994860e-01, 1.67957757e-01, 4.05030664e-02,\n        2.43670958e-02, 1.13422359e-02, 4.34249801e-03, 2.34529642e-03,\n        1.89836527e-03, 1.08557922e-03, 9.33857827e-04, 5.80825992e-04,\n        4.39777189e-04, 3.68221598e-04, 3.49847263e-04, 2.53562413e-04,\n        2.09806420e-04, 1.94004483e-04, 1.55790686e-04, 1.42688967e-04,\n        1.31743372e-04, 1.05355449e-04, 9.31827381e-05, 8.74572888e-05,\n        8.15766945e-05, 7.19818764e-05, 6.56479480e-05, 5.67727270e-05,\n        5.34645921e-05, 5.13552674e-05, 5.08735441e-05, 4.64097143e-05,\n        4.31595493e-05, 4.16782342e-05, 3.40198499e-05, 3.28355303e-05,\n        3.20072718e-05, 2.72846195e-05, 2.49601327e-05, 2.37773450e-05,\n        2.28731271e-05, 1.93054741e-05, 1.92533642e-05, 1.85251396e-05,\n        1.67748439e-05, 1.60158515e-05, 1.51118533e-05, 1.45522741e-05,\n        1.31160830e-05, 1.19272371e-05, 1.10114449e-05, 1.03634080e-05,\n        9.64787599e-06, 9.38851544e-06, 8.99492550e-06, 8.96692172e-06,\n        7.68575440e-06, 6.75756586e-06, 6.50418173e-06, 5.94688231e-06,\n        5.59118430e-06, 5.38390563e-06, 4.23776893e-06, 3.65709435e-06],\n       [5.41107727e-01, 7.41102587e-01, 9.09060344e-01, 9.49563410e-01,\n        9.73930506e-01, 9.85272742e-01, 9.89615240e-01, 9.91960536e-01,\n        9.93858902e-01, 9.94944481e-01, 9.95878339e-01, 9.96459165e-01,\n        9.96898942e-01, 9.97267163e-01, 9.97617011e-01, 9.97870573e-01,\n        9.98080379e-01, 9.98274384e-01, 9.98430175e-01, 9.98572864e-01,\n        9.98704607e-01, 9.98809962e-01, 9.98903145e-01, 9.98990602e-01,\n        9.99072179e-01, 9.99144161e-01, 9.99209809e-01, 9.99266582e-01,\n        9.99320046e-01, 9.99371402e-01, 9.99422275e-01, 9.99468685e-01,\n        9.99511844e-01, 9.99553523e-01, 9.99587542e-01, 9.99620378e-01,\n        9.99652385e-01, 9.99679670e-01, 9.99704630e-01, 9.99728407e-01,\n        9.99751280e-01, 9.99770586e-01, 9.99789839e-01, 9.99808364e-01,\n        9.99825139e-01, 9.99841155e-01, 9.99856267e-01, 9.99870819e-01,\n        9.99883935e-01, 9.99895863e-01, 9.99906874e-01, 9.99917237e-01,\n        9.99926885e-01, 9.99936274e-01, 9.99945269e-01, 9.99954236e-01,\n        9.99961921e-01, 9.99968679e-01, 9.99975183e-01, 9.99981130e-01,\n        9.99986721e-01, 9.99992105e-01, 9.99996343e-01, 1.00000000e+00]])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink_layer(layer_no=2, mid_layers=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:51:26.930875360Z",
     "start_time": "2023-07-01T17:51:25.211784558Z"
    }
   },
   "id": "d04d9cfbf072311a"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.002003157278522849\n",
      "choosen eigenvalues weight = 0.9998424184481154\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[3.07208001e-01, 2.72870291e-01, 2.28772508e-01, 9.78029362e-02,\n        4.36307817e-02, 2.42746555e-02, 8.96494246e-03, 5.77804621e-03,\n        4.11709096e-03, 2.67588362e-03, 1.10984865e-03, 5.24515200e-04,\n        4.96975730e-04, 3.48865837e-04, 2.83119196e-04, 1.96321832e-04,\n        1.73138622e-04, 1.33447728e-04, 7.85959138e-05, 7.26186205e-05,\n        4.95241965e-05, 4.39073251e-05, 3.99645860e-05, 3.58316103e-05,\n        2.70210053e-05, 2.57757963e-05, 2.28203668e-05, 2.07502908e-05,\n        1.95681933e-05, 1.58548726e-05, 1.45112601e-05, 1.43043448e-05,\n        1.32614879e-05, 1.22250092e-05, 1.16588637e-05, 9.25564671e-06,\n        8.45779871e-06, 8.16983703e-06, 7.35021179e-06, 6.68566808e-06,\n        6.00565246e-06, 5.85584591e-06, 5.36285327e-06, 5.21490360e-06,\n        4.86160243e-06, 4.50231430e-06, 4.48313376e-06, 4.23901106e-06,\n        3.86662156e-06, 3.66383083e-06, 3.44276582e-06, 3.32529609e-06,\n        3.03785773e-06, 2.73651737e-06, 2.61771173e-06, 2.44488428e-06,\n        2.30906946e-06, 2.15705700e-06, 2.10670129e-06, 1.93010160e-06,\n        1.73055231e-06, 1.58761744e-06, 1.54326755e-06, 1.49185995e-06],\n       [3.07208001e-01, 5.80078293e-01, 8.08850801e-01, 9.06653737e-01,\n        9.50284519e-01, 9.74559174e-01, 9.83524116e-01, 9.89302163e-01,\n        9.93419254e-01, 9.96095137e-01, 9.97204986e-01, 9.97729501e-01,\n        9.98226477e-01, 9.98575343e-01, 9.98858462e-01, 9.99054784e-01,\n        9.99227922e-01, 9.99361370e-01, 9.99439966e-01, 9.99512585e-01,\n        9.99562109e-01, 9.99606016e-01, 9.99645981e-01, 9.99681812e-01,\n        9.99708833e-01, 9.99734609e-01, 9.99757429e-01, 9.99778180e-01,\n        9.99797748e-01, 9.99813603e-01, 9.99828114e-01, 9.99842418e-01,\n        9.99855680e-01, 9.99867905e-01, 9.99879564e-01, 9.99888819e-01,\n        9.99897277e-01, 9.99905447e-01, 9.99912797e-01, 9.99919483e-01,\n        9.99925489e-01, 9.99931344e-01, 9.99936707e-01, 9.99941922e-01,\n        9.99946784e-01, 9.99951286e-01, 9.99955769e-01, 9.99960008e-01,\n        9.99963875e-01, 9.99967539e-01, 9.99970982e-01, 9.99974307e-01,\n        9.99977345e-01, 9.99980081e-01, 9.99982699e-01, 9.99985144e-01,\n        9.99987453e-01, 9.99989610e-01, 9.99991717e-01, 9.99993647e-01,\n        9.99995377e-01, 9.99996965e-01, 9.99998508e-01, 1.00000000e+00]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink_layer(layer_no=3, mid_layers=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:51:45.791089432Z",
     "start_time": "2023-07-01T17:51:44.660936460Z"
    }
   },
   "id": "8801dbb86b612722"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.04089765623211861\n",
      "choosen eigenvalues weight = 0.9980147880163952\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[3.04662521e-01, 1.58349194e-01, 1.25816134e-01, 9.70014777e-02,\n        6.28481699e-02, 5.88651191e-02, 3.85269118e-02, 3.02057014e-02,\n        2.32203763e-02, 1.75204364e-02, 1.38472211e-02, 1.13532790e-02,\n        9.55050552e-03, 6.97411320e-03, 5.98340613e-03, 4.93256677e-03,\n        4.54769485e-03, 3.10258562e-03, 2.44730850e-03, 2.03940546e-03,\n        1.69276736e-03, 1.41551110e-03, 1.34020977e-03, 1.07393348e-03,\n        8.89830611e-04, 7.15702445e-04, 6.60485034e-04, 6.44456786e-04,\n        5.34541169e-04, 5.11693313e-04, 5.02689231e-04, 4.40116380e-04,\n        3.75370118e-04, 3.57245122e-04, 3.29962898e-04, 3.24354880e-04,\n        3.03113508e-04, 2.84904555e-04, 2.59633762e-04, 2.47307453e-04,\n        2.34306045e-04, 2.24004384e-04, 2.14141117e-04, 1.97803662e-04,\n        1.86137153e-04, 1.74915546e-04, 1.67241141e-04, 1.57087846e-04,\n        1.53433159e-04, 1.48848485e-04, 1.41542437e-04, 1.35022027e-04,\n        1.20538861e-04, 1.14330715e-04, 1.10383463e-04, 1.06388091e-04,\n        1.00716471e-04, 1.00273252e-04, 9.59344493e-05, 9.44298345e-05,\n        9.17406873e-05, 8.72134151e-05, 8.07172145e-05, 7.96816705e-05,\n        7.47552870e-05, 7.35228054e-05, 7.10858386e-05, 6.92931043e-05,\n        6.46921027e-05, 6.20782504e-05, 6.14311138e-05, 5.86669320e-05,\n        5.85921687e-05, 5.56662139e-05, 5.45581599e-05, 5.34411441e-05,\n        5.00904475e-05, 4.60704078e-05, 4.50553056e-05, 4.36805115e-05,\n        4.30864960e-05, 4.15898231e-05, 4.07468386e-05, 3.88662883e-05,\n        3.74168239e-05, 3.67288383e-05, 3.52035548e-05, 3.32489043e-05,\n        3.20202719e-05, 3.07380902e-05, 3.04031147e-05, 2.96346272e-05,\n        2.89247595e-05, 2.78605460e-05, 2.76478807e-05, 2.59731900e-05,\n        2.53307277e-05, 2.43820981e-05, 2.36893306e-05, 2.29956225e-05,\n        2.26060635e-05, 2.23080910e-05, 2.09459573e-05, 2.03633344e-05,\n        1.99739658e-05, 1.92928433e-05, 1.78017881e-05, 1.74466823e-05,\n        1.67422514e-05, 1.64958847e-05, 1.63056943e-05, 1.57718378e-05,\n        1.48572937e-05, 1.42671623e-05, 1.39332679e-05, 1.35687547e-05,\n        1.30702131e-05, 1.28182791e-05, 1.18046187e-05, 1.15754466e-05,\n        1.11154166e-05, 1.03553569e-05, 9.83305266e-06, 9.54640525e-06,\n        9.23951493e-06, 8.79549218e-06, 8.21768192e-06, 6.99201356e-06],\n       [3.04662521e-01, 4.63011715e-01, 5.88827849e-01, 6.85829327e-01,\n        7.48677497e-01, 8.07542616e-01, 8.46069528e-01, 8.76275229e-01,\n        8.99495605e-01, 9.17016042e-01, 9.30863263e-01, 9.42216542e-01,\n        9.51767047e-01, 9.58741161e-01, 9.64724567e-01, 9.69657133e-01,\n        9.74204828e-01, 9.77307414e-01, 9.79754722e-01, 9.81794128e-01,\n        9.83486895e-01, 9.84902406e-01, 9.86242616e-01, 9.87316550e-01,\n        9.88206380e-01, 9.88922083e-01, 9.89582568e-01, 9.90227025e-01,\n        9.90761566e-01, 9.91273259e-01, 9.91775948e-01, 9.92216065e-01,\n        9.92591435e-01, 9.92948680e-01, 9.93278643e-01, 9.93602998e-01,\n        9.93906111e-01, 9.94191016e-01, 9.94450649e-01, 9.94697957e-01,\n        9.94932263e-01, 9.95156267e-01, 9.95370408e-01, 9.95568212e-01,\n        9.95754349e-01, 9.95929265e-01, 9.96096506e-01, 9.96253594e-01,\n        9.96407027e-01, 9.96555875e-01, 9.96697418e-01, 9.96832440e-01,\n        9.96952979e-01, 9.97067309e-01, 9.97177693e-01, 9.97284081e-01,\n        9.97384797e-01, 9.97485071e-01, 9.97581005e-01, 9.97675435e-01,\n        9.97767176e-01, 9.97854389e-01, 9.97935106e-01, 9.98014788e-01,\n        9.98089543e-01, 9.98163066e-01, 9.98234152e-01, 9.98303445e-01,\n        9.98368137e-01, 9.98430215e-01, 9.98491647e-01, 9.98550313e-01,\n        9.98608906e-01, 9.98664572e-01, 9.98719130e-01, 9.98772571e-01,\n        9.98822662e-01, 9.98868732e-01, 9.98913787e-01, 9.98957468e-01,\n        9.99000554e-01, 9.99042144e-01, 9.99082891e-01, 9.99121757e-01,\n        9.99159174e-01, 9.99195903e-01, 9.99231106e-01, 9.99264355e-01,\n        9.99296376e-01, 9.99327114e-01, 9.99357517e-01, 9.99387151e-01,\n        9.99416076e-01, 9.99443937e-01, 9.99471585e-01, 9.99497558e-01,\n        9.99522889e-01, 9.99547271e-01, 9.99570960e-01, 9.99593956e-01,\n        9.99616562e-01, 9.99638870e-01, 9.99659816e-01, 9.99680179e-01,\n        9.99700153e-01, 9.99719446e-01, 9.99737248e-01, 9.99754694e-01,\n        9.99771437e-01, 9.99787932e-01, 9.99804238e-01, 9.99820010e-01,\n        9.99834867e-01, 9.99849134e-01, 9.99863068e-01, 9.99876637e-01,\n        9.99889707e-01, 9.99902525e-01, 9.99914330e-01, 9.99925905e-01,\n        9.99937020e-01, 9.99947376e-01, 9.99957209e-01, 9.99966755e-01,\n        9.99975995e-01, 9.99984790e-01, 9.99993008e-01, 1.00000000e+00]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink_layer(layer_no=4, mid_layers=64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:52:41.809413989Z",
     "start_time": "2023-07-01T17:52:41.353455209Z"
    }
   },
   "id": "b40f2fa536bb8f42"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff = 0.03849208354949951\n",
      "choosen eigenvalues weight = 0.9980337282775918\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[3.06424392e-01, 2.26783453e-01, 1.34995127e-01, 1.03324974e-01,\n        7.42818076e-02, 4.05715877e-02, 2.12504356e-02, 1.93831084e-02,\n        1.13350797e-02, 9.61845711e-03, 9.21366802e-03, 6.96919250e-03,\n        4.95609886e-03, 3.95573996e-03, 3.65463696e-03, 2.60785745e-03,\n        2.19521496e-03, 1.92252897e-03, 1.40597379e-03, 1.24498059e-03,\n        1.06533565e-03, 9.26767486e-04, 7.83990644e-04, 6.27024586e-04,\n        5.99851624e-04, 5.61611956e-04, 5.11547709e-04, 4.33884431e-04,\n        4.12262552e-04, 3.78815696e-04, 3.45213791e-04, 3.27943589e-04,\n        3.18604491e-04, 2.86902903e-04, 2.73597741e-04, 2.63109562e-04,\n        2.55781610e-04, 2.39160697e-04, 2.12447484e-04, 2.11253951e-04,\n        1.93599493e-04, 1.81650870e-04, 1.72784248e-04, 1.64902847e-04,\n        1.63063376e-04, 1.55786717e-04, 1.49621956e-04, 1.45030318e-04,\n        1.32146912e-04, 1.23697265e-04, 1.19250965e-04, 1.16048102e-04,\n        1.12558827e-04, 1.05605648e-04, 1.03498235e-04, 9.69852216e-05,\n        9.22344701e-05, 9.06322423e-05, 8.84632812e-05, 8.47415619e-05,\n        8.38537968e-05, 7.96570319e-05, 7.58785138e-05, 7.26145434e-05,\n        6.99505877e-05, 6.84218438e-05, 6.63022843e-05, 6.43725393e-05,\n        6.26418151e-05, 5.92231389e-05, 5.76847227e-05, 5.62635431e-05,\n        5.33908598e-05, 5.20035825e-05, 5.08583863e-05, 4.97283279e-05,\n        4.78095430e-05, 4.70469934e-05, 4.43970574e-05, 4.37558080e-05,\n        4.17564324e-05, 4.13233961e-05, 4.07496893e-05, 4.00485255e-05,\n        3.77182537e-05, 3.71777988e-05, 3.65082367e-05, 3.49482402e-05,\n        3.31397556e-05, 3.23944484e-05, 3.12919089e-05, 3.04957050e-05,\n        2.85676473e-05, 2.79533558e-05, 2.76114285e-05, 2.69359238e-05,\n        2.61440418e-05, 2.47990641e-05, 2.42779891e-05, 2.31964862e-05,\n        2.26812109e-05, 2.24803934e-05, 2.16705487e-05, 2.11255588e-05,\n        2.00412926e-05, 1.93972806e-05, 1.84559093e-05, 1.81874846e-05,\n        1.72700774e-05, 1.69828987e-05, 1.66511936e-05, 1.61328171e-05,\n        1.59012183e-05, 1.57988838e-05, 1.51724756e-05, 1.43928110e-05,\n        1.38369867e-05, 1.34026835e-05, 1.28294451e-05, 1.23172989e-05,\n        1.17742999e-05, 1.16185590e-05, 1.10710719e-05, 1.05156747e-05,\n        1.00129558e-05, 9.18085399e-06, 8.52538720e-06, 7.95509105e-06],\n       [3.06424392e-01, 5.33207844e-01, 6.68202972e-01, 7.71527946e-01,\n        8.45809753e-01, 8.86381341e-01, 9.07631776e-01, 9.27014885e-01,\n        9.38349965e-01, 9.47968422e-01, 9.57182090e-01, 9.64151282e-01,\n        9.69107381e-01, 9.73063121e-01, 9.76717758e-01, 9.79325615e-01,\n        9.81520830e-01, 9.83443359e-01, 9.84849333e-01, 9.86094314e-01,\n        9.87159649e-01, 9.88086417e-01, 9.88870407e-01, 9.89497432e-01,\n        9.90097284e-01, 9.90658896e-01, 9.91170443e-01, 9.91604328e-01,\n        9.92016590e-01, 9.92395406e-01, 9.92740620e-01, 9.93068563e-01,\n        9.93387168e-01, 9.93674071e-01, 9.93947669e-01, 9.94210778e-01,\n        9.94466560e-01, 9.94705720e-01, 9.94918168e-01, 9.95129422e-01,\n        9.95323021e-01, 9.95504672e-01, 9.95677456e-01, 9.95842359e-01,\n        9.96005423e-01, 9.96161209e-01, 9.96310831e-01, 9.96455862e-01,\n        9.96588009e-01, 9.96711706e-01, 9.96830957e-01, 9.96947005e-01,\n        9.97059564e-01, 9.97165169e-01, 9.97268668e-01, 9.97365653e-01,\n        9.97457887e-01, 9.97548520e-01, 9.97636983e-01, 9.97721724e-01,\n        9.97805578e-01, 9.97885235e-01, 9.97961114e-01, 9.98033728e-01,\n        9.98103679e-01, 9.98172101e-01, 9.98238403e-01, 9.98302776e-01,\n        9.98365417e-01, 9.98424640e-01, 9.98482325e-01, 9.98538589e-01,\n        9.98591980e-01, 9.98643983e-01, 9.98694842e-01, 9.98744570e-01,\n        9.98792379e-01, 9.98839426e-01, 9.98883824e-01, 9.98927579e-01,\n        9.98969336e-01, 9.99010659e-01, 9.99051409e-01, 9.99091457e-01,\n        9.99129176e-01, 9.99166353e-01, 9.99202862e-01, 9.99237810e-01,\n        9.99270950e-01, 9.99303344e-01, 9.99334636e-01, 9.99365132e-01,\n        9.99393699e-01, 9.99421653e-01, 9.99449264e-01, 9.99476200e-01,\n        9.99502344e-01, 9.99527143e-01, 9.99551421e-01, 9.99574618e-01,\n        9.99597299e-01, 9.99619779e-01, 9.99641450e-01, 9.99662575e-01,\n        9.99682617e-01, 9.99702014e-01, 9.99720470e-01, 9.99738657e-01,\n        9.99755927e-01, 9.99772910e-01, 9.99789561e-01, 9.99805694e-01,\n        9.99821596e-01, 9.99837394e-01, 9.99852567e-01, 9.99866960e-01,\n        9.99880797e-01, 9.99894199e-01, 9.99907029e-01, 9.99919346e-01,\n        9.99931120e-01, 9.99942739e-01, 9.99953810e-01, 9.99964326e-01,\n        9.99974339e-01, 9.99983520e-01, 9.99992045e-01, 1.00000000e+00]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink_layer(layer_no=5, mid_layers=64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:52:47.727522768Z",
     "start_time": "2023-07-01T17:52:47.617019999Z"
    }
   },
   "id": "70237d435c2ce104"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def test_layers(mirror_count: int = 2) -> float:\n",
    "    for i, layer in enumerate(model.paraller_layers):\n",
    "        layer.use_real_layer = i >= mirror_count\n",
    "    return TrainHelper.test(model, test_data, device='cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:52:51.081636823Z",
     "start_time": "2023-07-01T17:52:51.040757220Z"
    }
   },
   "id": "e5884b1798857506"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.9833, 0.9833, 0.9829, 0.9828, 0.9829, 0.9829, 0.983]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[test_layers(i) for i in range(7)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T17:52:57.917106480Z",
     "start_time": "2023-07-01T17:52:52.335962568Z"
    }
   },
   "id": "f891c7cffeb13b28"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
