{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Optional, Tuple, List\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-08T20:53:15.041707919Z",
     "start_time": "2023-07-08T20:53:15.036514734Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.0.1+cu117'"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-08T20:53:15.041937469Z",
     "start_time": "2023-07-08T20:53:15.036758204Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='../models/mnist',\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='../models/mnist',\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-08T20:53:15.094477263Z",
     "start_time": "2023-07-08T20:53:15.036889514Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "class TrainHelper:\n",
    "    @staticmethod\n",
    "    def train(cnn: nn.Module,\n",
    "              *,\n",
    "              epochs: int,\n",
    "              train_dataset: datasets.MNIST,\n",
    "              test_dataset: Optional[datasets.MNIST] = None,\n",
    "              print_results: bool = True,\n",
    "              batch_size: int,\n",
    "              device_name: str, \n",
    "              writer: Optional[SummaryWriter] = None) -> List[float]:\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=1)\n",
    "\n",
    "        device = torch.device(device_name)\n",
    "\n",
    "        cnn.to(device)\n",
    "        cnn.train()\n",
    "\n",
    "        optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        eval_results: List[float] = []\n",
    "\n",
    "        steps = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in train_loader:\n",
    "                images = Variable(images.to(device))\n",
    "                labels = Variable(labels.to(device))\n",
    "\n",
    "                output = cnn(images)\n",
    "                loss = loss_func(output, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                steps += 1\n",
    "                if writer is not None:\n",
    "                    writer.add_scalar(\"training loss\", loss.item(), steps)\n",
    "\n",
    "            if test_dataset is not None:\n",
    "                eval_result = TrainHelper.test(cnn, test_dataset, device)\n",
    "                eval_results.append(eval_result)\n",
    "                if writer is not None:\n",
    "                    writer.add_scalar(\"test accuracy\", eval_result, steps)\n",
    "                if print_results:\n",
    "                    print(f\"epoch {epoch}, accuracy = {eval_result}, loss = {loss.detach()}\")\n",
    "                cnn.train()\n",
    "\n",
    "        return eval_results\n",
    "\n",
    "    @staticmethod\n",
    "    def test(cnn: nn.Module, test_dataset: datasets.MNIST, device=None) -> float:\n",
    "        cnn.eval()\n",
    "        loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=1)\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "\n",
    "        for images, labels in loader:\n",
    "            if device is not None:\n",
    "                images = images.to(device)\n",
    "\n",
    "            results = cnn(images)\n",
    "            predictions = results.detach().cpu().numpy().argmax(axis=1)\n",
    "            oks = (predictions == labels.numpy()).sum()\n",
    "            correct += oks\n",
    "            incorrect += len(predictions) - oks\n",
    "\n",
    "        return correct / (correct + incorrect)\n",
    "\n",
    "    @staticmethod\n",
    "    def train_models(models: List[nn.Module], device_name: str) -> Tuple[int, float]:\n",
    "        \"\"\"\n",
    "        generator yields pair (trainable parameters count, best accuracy) for each network\n",
    "        :param device_name: 'cuda' or 'cpu'\n",
    "        \"\"\"\n",
    "        assert len(models) > 0\n",
    "\n",
    "        for model in models:\n",
    "            start = time.time()\n",
    "            eval_results = TrainHelper.train(\n",
    "                cnn=model,\n",
    "                epochs=20,\n",
    "                train_dataset=train_data,\n",
    "                test_dataset=test_data,\n",
    "                batch_size=2048,\n",
    "                device_name=device_name,\n",
    "                print_results=False\n",
    "            )\n",
    "            end = time.time()\n",
    "            best_acc = max(eval_results)\n",
    "            params_count = TrainHelper.total_parameters_count(model)\n",
    "            print(f\"best accuracy = {best_acc}, parameters = {params_count}, training time = {end - start}\")\n",
    "            yield params_count, best_acc\n",
    "\n",
    "    @staticmethod\n",
    "    def total_parameters_count(model: nn.Module) -> int:\n",
    "        return sum(np.prod(p.size()) for p in model.parameters())\n",
    "\n",
    "    @staticmethod\n",
    "    def print_parameters(model: nn.Module):\n",
    "        print(f\"total parameters = {TrainHelper.total_parameters_count(model)}\")\n",
    "        for p in model.parameters():\n",
    "            print(f\"size {np.prod(p.size())}: {p.size()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-08T20:53:15.113225432Z",
     "start_time": "2023-07-08T20:53:15.095018654Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "class MyConvModel(nn.Module):\n",
    "    def __init__(self, channels: int):\n",
    "        super(MyConvModel, self).__init__()\n",
    "\n",
    "        c = channels\n",
    "        self.layers = nn.Sequential(\n",
    "            self.conv(1, c, kernel_size=3),         # 28 - 26\n",
    "            self.conv(c, c, kernel_size=3),         # 26 - 24\n",
    "            nn.MaxPool2d(2),                        # 24 - 12\n",
    "\n",
    "            self.conv(c, c * 2, kernel_size=3),     # 12 - 10\n",
    "            self.conv(c * 2, c * 2, kernel_size=3), # 10 - 8\n",
    "            nn.MaxPool2d(2),                        # 8 - 4\n",
    "\n",
    "            self.conv(c * 2, c * 4, kernel_size=3), # 4 - 2\n",
    "            self.conv(c * 4, c * 4, kernel_size=2), # 2 - 1\n",
    "\n",
    "            nn.Conv2d(c * 4, 10, kernel_size=1, padding='valid', bias=True),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def conv(self, in_ch: int, out_ch: int, *, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding='valid', bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layers(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-08T20:53:15.144702855Z",
     "start_time": "2023-07-08T20:53:15.099903799Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, accuracy = 0.3948, loss = 0.5082036256790161\n",
      "epoch 1, accuracy = 0.9732, loss = 0.22147969901561737\n",
      "epoch 2, accuracy = 0.9844, loss = 0.12899404764175415\n",
      "epoch 3, accuracy = 0.9864, loss = 0.07547627389431\n",
      "epoch 4, accuracy = 0.9883, loss = 0.06863679736852646\n",
      "epoch 5, accuracy = 0.9906, loss = 0.045335058122873306\n",
      "epoch 6, accuracy = 0.9924, loss = 0.03798489272594452\n",
      "epoch 7, accuracy = 0.9923, loss = 0.025235455483198166\n",
      "epoch 8, accuracy = 0.993, loss = 0.024531718343496323\n",
      "epoch 9, accuracy = 0.9936, loss = 0.026238955557346344\n"
     ]
    }
   ],
   "source": [
    "model = MyConvModel(16)\n",
    "with SummaryWriter(f'my_mnist/{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}') as writer:\n",
    "    writer.add_custom_scalars_multilinechart(tags=['test accuracy', 'training loss'])\n",
    "    writer.add_text('model architecture', f'```\\n{str(model)}\\n```')\n",
    "    TrainHelper.train(model, epochs=10, train_dataset=train_data, test_dataset=test_data, print_results=True, batch_size=2000, device_name='cuda', writer=writer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-08T20:53:59.400198020Z",
     "start_time": "2023-07-08T20:53:15.140457360Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
